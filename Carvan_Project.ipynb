{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import date\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = r\"C:\\Users\\Mr. Jarvis\\Desktop\\python project\\project 2\\carvan_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = r\"C:\\Users\\Mr. Jarvis\\Desktop\\python project\\project 2\\carvan_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_train = pd.read_csv(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_test = pd.read_csv(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V77</th>\n",
       "      <th>V78</th>\n",
       "      <th>V79</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  ...  V77  V78  V79  V80  V81  V82  \\\n",
       "0  33   1   3   2   8   0   5   1   3    7  ...    0    0    0    1    0    0   \n",
       "1  37   1   2   2   8   1   4   1   4    6  ...    0    0    0    1    0    0   \n",
       "2  37   1   2   2   8   0   4   2   4    3  ...    0    0    0    1    0    0   \n",
       "3   9   1   3   3   3   2   3   2   4    5  ...    0    0    0    1    0    0   \n",
       "4  40   1   4   2  10   1   4   1   4    7  ...    0    0    0    1    0    0   \n",
       "\n",
       "   V83  V84  V85  V86  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V76</th>\n",
       "      <th>V77</th>\n",
       "      <th>V78</th>\n",
       "      <th>V79</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  ...  V76  V77  V78  V79  V80  V81  \\\n",
       "0  33   1   4   2   8   0   6   0   3    5  ...    0    0    0    0    1    0   \n",
       "1   6   1   3   2   2   0   5   0   4    5  ...    2    0    0    0    1    0   \n",
       "2  39   1   3   3   9   1   4   2   3    5  ...    1    0    0    0    1    0   \n",
       "3   9   1   2   3   3   2   3   2   4    5  ...    0    0    0    0    1    0   \n",
       "4  31   1   2   4   7   0   2   0   7    9  ...    0    0    0    0    1    0   \n",
       "\n",
       "   V82  V83  V84  V85  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.max_rows',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>V38</th>\n",
       "      <th>V39</th>\n",
       "      <th>V40</th>\n",
       "      <th>V41</th>\n",
       "      <th>V42</th>\n",
       "      <th>V43</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V46</th>\n",
       "      <th>V47</th>\n",
       "      <th>V48</th>\n",
       "      <th>V49</th>\n",
       "      <th>V50</th>\n",
       "      <th>V51</th>\n",
       "      <th>V52</th>\n",
       "      <th>V53</th>\n",
       "      <th>V54</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "      <th>V65</th>\n",
       "      <th>V66</th>\n",
       "      <th>V67</th>\n",
       "      <th>V68</th>\n",
       "      <th>V69</th>\n",
       "      <th>V70</th>\n",
       "      <th>V71</th>\n",
       "      <th>V72</th>\n",
       "      <th>V73</th>\n",
       "      <th>V74</th>\n",
       "      <th>V75</th>\n",
       "      <th>V76</th>\n",
       "      <th>V77</th>\n",
       "      <th>V78</th>\n",
       "      <th>V79</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  V11  V12  V13  V14  V15  V16  V17  \\\n",
       "0  33   1   4   2   8   0   6   0   3    5    0    4    1    1    8    2    2   \n",
       "1   6   1   3   2   2   0   5   0   4    5    2    2    1    4    5    5    4   \n",
       "2  39   1   3   3   9   1   4   2   3    5    2    3    2    3    6    2    4   \n",
       "3   9   1   2   3   3   2   3   2   4    5    4    1    2    4    4    2    4   \n",
       "4  31   1   2   4   7   0   2   0   7    9    0    0    0    6    3    0    0   \n",
       "\n",
       "   V18  V19  V20  V21  V22  V23  V24  V25  V26  V27  V28  V29  V30  V31  V32  \\\n",
       "0    6    0    0    1    2    6    1    0    2    1    5    3    1    8    8   \n",
       "1    0    5    0    0    4    0    0    4    3    0    2    1    3    6    9   \n",
       "2    4    2    1    1    3    2    2    1    1    5    2    1    1    8    6   \n",
       "3    4    2    1    1    5    1    2    3    1    3    2    2    3    6    7   \n",
       "4    9    0    0    0    2    4    4    0    0    0    7    2    9    0    7   \n",
       "\n",
       "   V33  V34  V35  V36  V37  V38  V39  V40  V41  V42  V43  V44  V45  V46  V47  \\\n",
       "0    1    1    8    1    3    3    3    0    0    3    3    1    0    0    0   \n",
       "1    0    0    7    2    1    1    5    4    0    6    8    2    0    0    6   \n",
       "2    2    2    6    3    2    4    3    1    0    3    5    2    0    0    6   \n",
       "3    2    1    7    2    2    5    3    1    0    4    4    2    0    0    5   \n",
       "4    2    0    9    0    5    4    0    0    0    3    1    2    0    0    0   \n",
       "\n",
       "   V48  V49  V50  V51  V52  V53  V54  V55  V56  V57  V58  V59  V60  V61  V62  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0    0    4    0    0    0   \n",
       "1    0    4    0    0    0    0    0    3    0    0    0    4    0    0    0   \n",
       "2    0    0    0    0    0    0    0    4    0    0    0    4    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0    0    3    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0   \n",
       "\n",
       "   V63  V64  V65  V66  V67  V68  V69  V70  V71  V72  V73  V74  V75  V76  V77  \\\n",
       "0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1    0    0    1    0    0    1    0    1    0    0    0    0    0    2    0   \n",
       "2    0    0    1    0    0    1    0    0    0    0    0    0    0    1    0   \n",
       "3    0    0    1    0    0    1    0    0    0    0    0    0    0    0    0   \n",
       "4    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   V78  V79  V80  V81  V82  V83  V84  V85  \n",
       "0    0    0    1    0    0    0    0    0  \n",
       "1    0    0    1    0    0    0    0    0  \n",
       "2    0    0    1    0    0    0    0    0  \n",
       "3    0    0    1    0    0    0    0    0  \n",
       "4    0    0    1    0    0    0    0    0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1     0\n",
       "V2     0\n",
       "V3     0\n",
       "V4     0\n",
       "V5     0\n",
       "V6     0\n",
       "V7     0\n",
       "V8     0\n",
       "V9     0\n",
       "V10    0\n",
       "V11    0\n",
       "V12    0\n",
       "V13    0\n",
       "V14    0\n",
       "V15    0\n",
       "V16    0\n",
       "V17    0\n",
       "V18    0\n",
       "V19    0\n",
       "V20    0\n",
       "V21    0\n",
       "V22    0\n",
       "V23    0\n",
       "V24    0\n",
       "V25    0\n",
       "V26    0\n",
       "V27    0\n",
       "V28    0\n",
       "V29    0\n",
       "V30    0\n",
       "V31    0\n",
       "V32    0\n",
       "V33    0\n",
       "V34    0\n",
       "V35    0\n",
       "V36    0\n",
       "V37    0\n",
       "V38    0\n",
       "V39    0\n",
       "V40    0\n",
       "V41    0\n",
       "V42    0\n",
       "V43    0\n",
       "V44    0\n",
       "V45    0\n",
       "V46    0\n",
       "V47    0\n",
       "V48    0\n",
       "V49    0\n",
       "V50    0\n",
       "V51    0\n",
       "V52    0\n",
       "V53    0\n",
       "V54    0\n",
       "V55    0\n",
       "V56    0\n",
       "V57    0\n",
       "V58    0\n",
       "V59    0\n",
       "V60    0\n",
       "V61    0\n",
       "V62    0\n",
       "V63    0\n",
       "V64    0\n",
       "V65    0\n",
       "V66    0\n",
       "V67    0\n",
       "V68    0\n",
       "V69    0\n",
       "V70    0\n",
       "V71    0\n",
       "V72    0\n",
       "V73    0\n",
       "V74    0\n",
       "V75    0\n",
       "V76    0\n",
       "V77    0\n",
       "V78    0\n",
       "V79    0\n",
       "V80    0\n",
       "V81    0\n",
       "V82    0\n",
       "V83    0\n",
       "V84    0\n",
       "V85    0\n",
       "V86    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1     0\n",
       "V2     0\n",
       "V3     0\n",
       "V4     0\n",
       "V5     0\n",
       "V6     0\n",
       "V7     0\n",
       "V8     0\n",
       "V9     0\n",
       "V10    0\n",
       "V11    0\n",
       "V12    0\n",
       "V13    0\n",
       "V14    0\n",
       "V15    0\n",
       "V16    0\n",
       "V17    0\n",
       "V18    0\n",
       "V19    0\n",
       "V20    0\n",
       "V21    0\n",
       "V22    0\n",
       "V23    0\n",
       "V24    0\n",
       "V25    0\n",
       "V26    0\n",
       "V27    0\n",
       "V28    0\n",
       "V29    0\n",
       "V30    0\n",
       "V31    0\n",
       "V32    0\n",
       "V33    0\n",
       "V34    0\n",
       "V35    0\n",
       "V36    0\n",
       "V37    0\n",
       "V38    0\n",
       "V39    0\n",
       "V40    0\n",
       "V41    0\n",
       "V42    0\n",
       "V43    0\n",
       "V44    0\n",
       "V45    0\n",
       "V46    0\n",
       "V47    0\n",
       "V48    0\n",
       "V49    0\n",
       "V50    0\n",
       "V51    0\n",
       "V52    0\n",
       "V53    0\n",
       "V54    0\n",
       "V55    0\n",
       "V56    0\n",
       "V57    0\n",
       "V58    0\n",
       "V59    0\n",
       "V60    0\n",
       "V61    0\n",
       "V62    0\n",
       "V63    0\n",
       "V64    0\n",
       "V65    0\n",
       "V66    0\n",
       "V67    0\n",
       "V68    0\n",
       "V69    0\n",
       "V70    0\n",
       "V71    0\n",
       "V72    0\n",
       "V73    0\n",
       "V74    0\n",
       "V75    0\n",
       "V76    0\n",
       "V77    0\n",
       "V78    0\n",
       "V79    0\n",
       "V80    0\n",
       "V81    0\n",
       "V82    0\n",
       "V83    0\n",
       "V84    0\n",
       "V85    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5822, 86)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 85)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       33\n",
       "1       37\n",
       "2       37\n",
       "3        9\n",
       "4       40\n",
       "        ..\n",
       "5817    36\n",
       "5818    35\n",
       "5819    33\n",
       "5820    34\n",
       "5821    33\n",
       "Name: V1, Length: 5822, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_train['V1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5822, 86)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 85)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31',\n",
       "       'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41',\n",
       "       'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51',\n",
       "       'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61',\n",
       "       'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71',\n",
       "       'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81',\n",
       "       'V82', 'V83', 'V84', 'V85', 'V86'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31',\n",
       "       'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41',\n",
       "       'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51',\n",
       "       'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61',\n",
       "       'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71',\n",
       "       'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81',\n",
       "       'V82', 'V83', 'V84', 'V85'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_test['V86']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_train['data'] = 'train'\n",
    "bd_test['data'] = 'test'\n",
    "bd_test=bd_test[bd_train.columns] # the columns in the two data frames should\n",
    "#be in the same order to enable concatenation\n",
    "bd_all=pd.concat([bd_train,bd_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>V38</th>\n",
       "      <th>V39</th>\n",
       "      <th>V40</th>\n",
       "      <th>V41</th>\n",
       "      <th>V42</th>\n",
       "      <th>V43</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V46</th>\n",
       "      <th>V47</th>\n",
       "      <th>V48</th>\n",
       "      <th>V49</th>\n",
       "      <th>V50</th>\n",
       "      <th>V51</th>\n",
       "      <th>V52</th>\n",
       "      <th>V53</th>\n",
       "      <th>V54</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "      <th>V65</th>\n",
       "      <th>V66</th>\n",
       "      <th>V67</th>\n",
       "      <th>V68</th>\n",
       "      <th>V69</th>\n",
       "      <th>V70</th>\n",
       "      <th>V71</th>\n",
       "      <th>V72</th>\n",
       "      <th>V73</th>\n",
       "      <th>V74</th>\n",
       "      <th>V75</th>\n",
       "      <th>V76</th>\n",
       "      <th>V77</th>\n",
       "      <th>V78</th>\n",
       "      <th>V79</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  V11  V12  V13  V14  V15  V16  V17  \\\n",
       "0  33   1   3   2   8   0   5   1   3    7    0    2    1    2    6    1    2   \n",
       "1  37   1   2   2   8   1   4   1   4    6    2    2    0    4    5    0    5   \n",
       "2  37   1   2   2   8   0   4   2   4    3    2    4    4    4    2    0    5   \n",
       "3   9   1   3   3   3   2   3   2   4    5    2    2    2    3    4    3    4   \n",
       "4  40   1   4   2  10   1   4   1   4    7    1    2    2    4    4    5    4   \n",
       "\n",
       "   V18  V19  V20  V21  V22  V23  V24  V25  V26  V27  V28  V29  V30  V31  V32  \\\n",
       "0    7    1    0    1    2    5    2    1    1    2    6    1    1    8    8   \n",
       "1    4    0    0    0    5    0    4    0    2    3    5    0    2    7    7   \n",
       "2    4    0    0    0    7    0    2    0    5    0    4    0    7    2    7   \n",
       "3    2    4    0    0    3    1    2    3    2    1    4    0    5    4    9   \n",
       "4    0    0    5    4    0    0    0    9    0    0    0    0    4    5    6   \n",
       "\n",
       "   V33  V34  V35  V36  V37  V38  V39  V40  V41  V42  V43  V44  V45  V46  V47  \\\n",
       "0    0    1    8    1    0    4    5    0    0    4    3    0    0    0    6   \n",
       "1    1    2    6    3    2    0    5    2    0    5    4    2    0    0    0   \n",
       "2    0    2    9    0    4    5    0    0    0    3    4    2    0    0    6   \n",
       "3    0    0    7    2    1    5    3    0    0    4    4    0    0    0    6   \n",
       "4    2    1    5    4    0    0    9    0    0    6    3    0    0    0    0   \n",
       "\n",
       "   V48  V49  V50  V51  V52  V53  V54  V55  V56  V57  V58  V59  V60  V61  V62  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0    0    5    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0    0    6    0    0    0   \n",
       "\n",
       "   V63  V64  V65  V66  V67  V68  V69  V70  V71  V72  V73  V74  V75  V76  V77  \\\n",
       "0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0   \n",
       "1    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2    0    0    1    0    0    1    0    0    0    0    0    0    0    0    0   \n",
       "3    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   V78  V79  V80  V81  V82  V83  V84  V85  V86   data  \n",
       "0    0    0    1    0    0    0    0    0  0.0  train  \n",
       "1    0    0    1    0    0    0    0    0  0.0  train  \n",
       "2    0    0    1    0    0    0    0    0  0.0  train  \n",
       "3    0    0    1    0    0    0    0    0  0.0  train  \n",
       "4    0    0    1    0    0    0    0    0  0.0  train  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>V38</th>\n",
       "      <th>V39</th>\n",
       "      <th>V40</th>\n",
       "      <th>V41</th>\n",
       "      <th>V42</th>\n",
       "      <th>V43</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V46</th>\n",
       "      <th>V47</th>\n",
       "      <th>V48</th>\n",
       "      <th>V49</th>\n",
       "      <th>V50</th>\n",
       "      <th>V51</th>\n",
       "      <th>V52</th>\n",
       "      <th>V53</th>\n",
       "      <th>V54</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "      <th>V65</th>\n",
       "      <th>V66</th>\n",
       "      <th>V67</th>\n",
       "      <th>V68</th>\n",
       "      <th>V69</th>\n",
       "      <th>V70</th>\n",
       "      <th>V71</th>\n",
       "      <th>V72</th>\n",
       "      <th>V73</th>\n",
       "      <th>V74</th>\n",
       "      <th>V75</th>\n",
       "      <th>V76</th>\n",
       "      <th>V77</th>\n",
       "      <th>V78</th>\n",
       "      <th>V79</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  V11  V12  V13  V14  V15  V16  V17  \\\n",
       "0  33   1   3   2   8   0   5   1   3    7    0    2    1    2    6    1    2   \n",
       "1  37   1   2   2   8   1   4   1   4    6    2    2    0    4    5    0    5   \n",
       "2  37   1   2   2   8   0   4   2   4    3    2    4    4    4    2    0    5   \n",
       "3   9   1   3   3   3   2   3   2   4    5    2    2    2    3    4    3    4   \n",
       "4  40   1   4   2  10   1   4   1   4    7    1    2    2    4    4    5    4   \n",
       "\n",
       "   V18  V19  V20  V21  V22  V23  V24  V25  V26  V27  V28  V29  V30  V31  V32  \\\n",
       "0    7    1    0    1    2    5    2    1    1    2    6    1    1    8    8   \n",
       "1    4    0    0    0    5    0    4    0    2    3    5    0    2    7    7   \n",
       "2    4    0    0    0    7    0    2    0    5    0    4    0    7    2    7   \n",
       "3    2    4    0    0    3    1    2    3    2    1    4    0    5    4    9   \n",
       "4    0    0    5    4    0    0    0    9    0    0    0    0    4    5    6   \n",
       "\n",
       "   V33  V34  V35  V36  V37  V38  V39  V40  V41  V42  V43  V44  V45  V46  V47  \\\n",
       "0    0    1    8    1    0    4    5    0    0    4    3    0    0    0    6   \n",
       "1    1    2    6    3    2    0    5    2    0    5    4    2    0    0    0   \n",
       "2    0    2    9    0    4    5    0    0    0    3    4    2    0    0    6   \n",
       "3    0    0    7    2    1    5    3    0    0    4    4    0    0    0    6   \n",
       "4    2    1    5    4    0    0    9    0    0    6    3    0    0    0    0   \n",
       "\n",
       "   V48  V49  V50  V51  V52  V53  V54  V55  V56  V57  V58  V59  V60  V61  V62  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0    0    5    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0    0    6    0    0    0   \n",
       "\n",
       "   V63  V64  V65  V66  V67  V68  V69  V70  V71  V72  V73  V74  V75  V76  V77  \\\n",
       "0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0   \n",
       "1    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2    0    0    1    0    0    1    0    0    0    0    0    0    0    0    0   \n",
       "3    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   V78  V79  V80  V81  V82  V83  V84  V85  V86   data  \n",
       "0    0    0    1    0    0    0    0    0  0.0  train  \n",
       "1    0    0    1    0    0    0    0    0  0.0  train  \n",
       "2    0    0    1    0    0    0    0    0  0.0  train  \n",
       "3    0    0    1    0    0    0    0    0  0.0  train  \n",
       "4    0    0    1    0    0    0    0    0  0.0  train  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>V38</th>\n",
       "      <th>V39</th>\n",
       "      <th>V40</th>\n",
       "      <th>V41</th>\n",
       "      <th>V42</th>\n",
       "      <th>V43</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V46</th>\n",
       "      <th>V47</th>\n",
       "      <th>V48</th>\n",
       "      <th>V49</th>\n",
       "      <th>V50</th>\n",
       "      <th>V51</th>\n",
       "      <th>V52</th>\n",
       "      <th>V53</th>\n",
       "      <th>V54</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "      <th>V65</th>\n",
       "      <th>V66</th>\n",
       "      <th>V67</th>\n",
       "      <th>V68</th>\n",
       "      <th>V69</th>\n",
       "      <th>V70</th>\n",
       "      <th>V71</th>\n",
       "      <th>V72</th>\n",
       "      <th>V73</th>\n",
       "      <th>V74</th>\n",
       "      <th>V75</th>\n",
       "      <th>V76</th>\n",
       "      <th>V77</th>\n",
       "      <th>V78</th>\n",
       "      <th>V79</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3995</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3996</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3997</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3998</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3999</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  V11  V12  V13  V14  V15  V16  \\\n",
       "3995  33   1   2   4   8   0   7   2   0    5    2    2    2    6    2    0   \n",
       "3996  24   1   2   3   5   1   5   1   3    4    2    4    4    4    2    2   \n",
       "3997  36   1   2   3   8   1   5   1   3    7    0    2    2    5    3    2   \n",
       "3998  33   1   3   3   8   1   4   2   3    7    1    2    2    3    4    1   \n",
       "3999   8   1   2   3   2   4   3   0   3    5    2    2    0    6    3    8   \n",
       "\n",
       "      V17  V18  V19  V20  V21  V22  V23  V24  V25  V26  V27  V28  V29  V30  \\\n",
       "3995    3    6    5    0    0    1    0    4    2    0    2    4    2    4   \n",
       "3996    4    4    2    0    0    3    3    3    1    1    2    5    1    7   \n",
       "3997    3    4    2    0    0    3    4    2    1    1    3    5    0    7   \n",
       "3998    3    5    1    1    1    2    3    3    2    2    2    4    1    4   \n",
       "3999    0    1    8    0    0    0    0    1    4    0    5    1    0    2   \n",
       "\n",
       "      V31  V32  V33  V34  V35  V36  V37  V38  V39  V40  V41  V42  V43  V44  \\\n",
       "3995    5    4    4    2    3    6    3    6    0    0    0    2    3    2   \n",
       "3996    2    6    0    3    7    2    3    3    2    2    0    4    2    0   \n",
       "3997    2    6    1    2    6    3    2    5    3    0    0    4    3    0   \n",
       "3998    5    6    2    2    7    2    1    4    4    1    0    4    3    0   \n",
       "3999    7    9    0    0    2    7    0    0    7    2    0    7    8    2   \n",
       "\n",
       "      V45  V46  V47  V48  V49  V50  V51  V52  V53  V54  V55  V56  V57  V58  \\\n",
       "3995    0    0    6    0    0    0    0    0    0    0    0    0    0    0   \n",
       "3996    0    0    6    0    0    0    0    0    0    0    6    0    0    0   \n",
       "3997    0    0    6    0    0    0    0    0    0    0    0    0    0    0   \n",
       "3998    0    0    6    0    0    0    0    0    0    0    0    0    0    0   \n",
       "3999    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      V59  V60  V61  V62  V63  V64  V65  V66  V67  V68  V69  V70  V71  V72  \\\n",
       "3995    3    0    0    0    0    0    1    0    0    1    0    0    0    0   \n",
       "3996    4    0    0    0    0    0    0    0    0    1    0    0    0    0   \n",
       "3997    3    0    0    0    1    0    0    0    0    1    0    0    0    0   \n",
       "3998    0    0    0    0    0    0    0    0    0    1    0    0    0    0   \n",
       "3999    4    0    0    0    0    0    1    0    0    0    0    0    0    0   \n",
       "\n",
       "      V73  V74  V75  V76  V77  V78  V79  V80  V81  V82  V83  V84  V85  V86  \\\n",
       "3995    0    0    0    0    0    0    0    1    0    0    0    0    0  NaN   \n",
       "3996    0    0    0    1    0    0    0    1    0    0    0    0    0  NaN   \n",
       "3997    0    0    0    0    0    0    0    1    0    0    0    1    0  NaN   \n",
       "3998    0    0    0    0    0    0    0    0    0    0    0    0    0  NaN   \n",
       "3999    0    0    0    0    0    0    0    1    0    0    0    0    0  NaN   \n",
       "\n",
       "      data  \n",
       "3995  test  \n",
       "3996  test  \n",
       "3997  test  \n",
       "3998  test  \n",
       "3999  test  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 87)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1        int64\n",
       "V2        int64\n",
       "V3        int64\n",
       "V4        int64\n",
       "V5        int64\n",
       "V6        int64\n",
       "V7        int64\n",
       "V8        int64\n",
       "V9        int64\n",
       "V10       int64\n",
       "V11       int64\n",
       "V12       int64\n",
       "V13       int64\n",
       "V14       int64\n",
       "V15       int64\n",
       "V16       int64\n",
       "V17       int64\n",
       "V18       int64\n",
       "V19       int64\n",
       "V20       int64\n",
       "V21       int64\n",
       "V22       int64\n",
       "V23       int64\n",
       "V24       int64\n",
       "V25       int64\n",
       "V26       int64\n",
       "V27       int64\n",
       "V28       int64\n",
       "V29       int64\n",
       "V30       int64\n",
       "V31       int64\n",
       "V32       int64\n",
       "V33       int64\n",
       "V34       int64\n",
       "V35       int64\n",
       "V36       int64\n",
       "V37       int64\n",
       "V38       int64\n",
       "V39       int64\n",
       "V40       int64\n",
       "V41       int64\n",
       "V42       int64\n",
       "V43       int64\n",
       "V44       int64\n",
       "V45       int64\n",
       "V46       int64\n",
       "V47       int64\n",
       "V48       int64\n",
       "V49       int64\n",
       "V50       int64\n",
       "V51       int64\n",
       "V52       int64\n",
       "V53       int64\n",
       "V54       int64\n",
       "V55       int64\n",
       "V56       int64\n",
       "V57       int64\n",
       "V58       int64\n",
       "V59       int64\n",
       "V60       int64\n",
       "V61       int64\n",
       "V62       int64\n",
       "V63       int64\n",
       "V64       int64\n",
       "V65       int64\n",
       "V66       int64\n",
       "V67       int64\n",
       "V68       int64\n",
       "V69       int64\n",
       "V70       int64\n",
       "V71       int64\n",
       "V72       int64\n",
       "V73       int64\n",
       "V74       int64\n",
       "V75       int64\n",
       "V76       int64\n",
       "V77       int64\n",
       "V78       int64\n",
       "V79       int64\n",
       "V80       int64\n",
       "V81       int64\n",
       "V82       int64\n",
       "V83       int64\n",
       "V84       int64\n",
       "V85       int64\n",
       "V86     float64\n",
       "data     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>V38</th>\n",
       "      <th>V39</th>\n",
       "      <th>V40</th>\n",
       "      <th>V41</th>\n",
       "      <th>V42</th>\n",
       "      <th>V43</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V46</th>\n",
       "      <th>V47</th>\n",
       "      <th>V48</th>\n",
       "      <th>V49</th>\n",
       "      <th>V50</th>\n",
       "      <th>V51</th>\n",
       "      <th>V52</th>\n",
       "      <th>V53</th>\n",
       "      <th>V54</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "      <th>V65</th>\n",
       "      <th>V66</th>\n",
       "      <th>V67</th>\n",
       "      <th>V68</th>\n",
       "      <th>V69</th>\n",
       "      <th>V70</th>\n",
       "      <th>V71</th>\n",
       "      <th>V72</th>\n",
       "      <th>V73</th>\n",
       "      <th>V74</th>\n",
       "      <th>V75</th>\n",
       "      <th>V76</th>\n",
       "      <th>V77</th>\n",
       "      <th>V78</th>\n",
       "      <th>V79</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.00000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.00000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>24.253207</td>\n",
       "      <td>1.108735</td>\n",
       "      <td>2.677561</td>\n",
       "      <td>2.996437</td>\n",
       "      <td>5.779067</td>\n",
       "      <td>0.700672</td>\n",
       "      <td>4.637650</td>\n",
       "      <td>1.050092</td>\n",
       "      <td>3.262981</td>\n",
       "      <td>6.188964</td>\n",
       "      <td>0.873142</td>\n",
       "      <td>2.286602</td>\n",
       "      <td>1.887294</td>\n",
       "      <td>3.237324</td>\n",
       "      <td>4.302891</td>\n",
       "      <td>1.484525</td>\n",
       "      <td>3.307269</td>\n",
       "      <td>4.592038</td>\n",
       "      <td>1.898799</td>\n",
       "      <td>0.403278</td>\n",
       "      <td>0.545714</td>\n",
       "      <td>2.877113</td>\n",
       "      <td>2.226532</td>\n",
       "      <td>2.291183</td>\n",
       "      <td>1.650682</td>\n",
       "      <td>1.595093</td>\n",
       "      <td>2.204744</td>\n",
       "      <td>3.742211</td>\n",
       "      <td>1.068214</td>\n",
       "      <td>4.187742</td>\n",
       "      <td>4.819487</td>\n",
       "      <td>6.022501</td>\n",
       "      <td>1.335980</td>\n",
       "      <td>1.956730</td>\n",
       "      <td>6.254327</td>\n",
       "      <td>2.750662</td>\n",
       "      <td>2.577072</td>\n",
       "      <td>3.505498</td>\n",
       "      <td>2.739462</td>\n",
       "      <td>0.808491</td>\n",
       "      <td>0.208002</td>\n",
       "      <td>3.80452</td>\n",
       "      <td>4.260334</td>\n",
       "      <td>0.764915</td>\n",
       "      <td>0.038892</td>\n",
       "      <td>0.073712</td>\n",
       "      <td>2.956424</td>\n",
       "      <td>0.054877</td>\n",
       "      <td>0.170841</td>\n",
       "      <td>0.008858</td>\n",
       "      <td>0.019344</td>\n",
       "      <td>0.093565</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.215027</td>\n",
       "      <td>0.202301</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.018733</td>\n",
       "      <td>0.023315</td>\n",
       "      <td>1.849420</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.015272</td>\n",
       "      <td>0.025351</td>\n",
       "      <td>0.016697</td>\n",
       "      <td>0.045408</td>\n",
       "      <td>0.400020</td>\n",
       "      <td>0.014050</td>\n",
       "      <td>0.021279</td>\n",
       "      <td>0.557218</td>\n",
       "      <td>0.011098</td>\n",
       "      <td>0.040216</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>0.011403</td>\n",
       "      <td>0.034413</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.071065</td>\n",
       "      <td>0.079821</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.004276</td>\n",
       "      <td>0.574018</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>0.03146</td>\n",
       "      <td>0.008450</td>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.059773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>12.918058</td>\n",
       "      <td>0.412101</td>\n",
       "      <td>0.780701</td>\n",
       "      <td>0.804660</td>\n",
       "      <td>2.874148</td>\n",
       "      <td>1.015107</td>\n",
       "      <td>1.721212</td>\n",
       "      <td>1.011156</td>\n",
       "      <td>1.606287</td>\n",
       "      <td>1.896070</td>\n",
       "      <td>0.961955</td>\n",
       "      <td>1.710674</td>\n",
       "      <td>1.779238</td>\n",
       "      <td>1.609139</td>\n",
       "      <td>1.984152</td>\n",
       "      <td>1.645968</td>\n",
       "      <td>1.723377</td>\n",
       "      <td>2.279839</td>\n",
       "      <td>1.814406</td>\n",
       "      <td>0.786792</td>\n",
       "      <td>1.106349</td>\n",
       "      <td>1.846703</td>\n",
       "      <td>1.748025</td>\n",
       "      <td>1.684008</td>\n",
       "      <td>1.742410</td>\n",
       "      <td>1.321487</td>\n",
       "      <td>1.534163</td>\n",
       "      <td>1.944900</td>\n",
       "      <td>1.298229</td>\n",
       "      <td>3.093127</td>\n",
       "      <td>3.093541</td>\n",
       "      <td>1.543980</td>\n",
       "      <td>1.213627</td>\n",
       "      <td>1.596842</td>\n",
       "      <td>2.000374</td>\n",
       "      <td>2.002960</td>\n",
       "      <td>2.073125</td>\n",
       "      <td>1.871365</td>\n",
       "      <td>1.950625</td>\n",
       "      <td>1.173771</td>\n",
       "      <td>0.561832</td>\n",
       "      <td>1.33093</td>\n",
       "      <td>1.998913</td>\n",
       "      <td>0.956555</td>\n",
       "      <td>0.356924</td>\n",
       "      <td>0.507818</td>\n",
       "      <td>2.921736</td>\n",
       "      <td>0.566108</td>\n",
       "      <td>0.888518</td>\n",
       "      <td>0.237556</td>\n",
       "      <td>0.200885</td>\n",
       "      <td>0.604350</td>\n",
       "      <td>0.215408</td>\n",
       "      <td>0.810899</td>\n",
       "      <td>0.910574</td>\n",
       "      <td>0.188699</td>\n",
       "      <td>0.213712</td>\n",
       "      <td>0.375350</td>\n",
       "      <td>1.881271</td>\n",
       "      <td>0.057058</td>\n",
       "      <td>0.244210</td>\n",
       "      <td>0.157198</td>\n",
       "      <td>0.211487</td>\n",
       "      <td>0.396983</td>\n",
       "      <td>0.492001</td>\n",
       "      <td>0.126058</td>\n",
       "      <td>0.144319</td>\n",
       "      <td>0.608575</td>\n",
       "      <td>0.129928</td>\n",
       "      <td>0.223622</td>\n",
       "      <td>0.068402</td>\n",
       "      <td>0.116251</td>\n",
       "      <td>0.249706</td>\n",
       "      <td>0.109954</td>\n",
       "      <td>0.267432</td>\n",
       "      <td>0.384431</td>\n",
       "      <td>0.067535</td>\n",
       "      <td>0.088764</td>\n",
       "      <td>0.071224</td>\n",
       "      <td>0.561255</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>0.077996</td>\n",
       "      <td>0.20907</td>\n",
       "      <td>0.092647</td>\n",
       "      <td>0.117728</td>\n",
       "      <td>0.237087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                V1           V2           V3           V4           V5  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean     24.253207     1.108735     2.677561     2.996437     5.779067   \n",
       "std      12.918058     0.412101     0.780701     0.804660     2.874148   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%      10.000000     1.000000     2.000000     2.000000     3.000000   \n",
       "50%      30.000000     1.000000     3.000000     3.000000     7.000000   \n",
       "75%      35.000000     1.000000     3.000000     3.000000     8.000000   \n",
       "max      41.000000    10.000000     6.000000     6.000000    10.000000   \n",
       "\n",
       "                V6           V7           V8           V9          V10  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      0.700672     4.637650     1.050092     3.262981     6.188964   \n",
       "std       1.015107     1.721212     1.011156     1.606287     1.896070   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     4.000000     0.000000     2.000000     5.000000   \n",
       "50%       0.000000     5.000000     1.000000     3.000000     6.000000   \n",
       "75%       1.000000     6.000000     2.000000     4.000000     7.000000   \n",
       "max       9.000000     9.000000     5.000000     9.000000     9.000000   \n",
       "\n",
       "               V11          V12          V13          V14          V15  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      0.873142     2.286602     1.887294     3.237324     4.302891   \n",
       "std       0.961955     1.710674     1.779238     1.609139     1.984152   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     1.000000     0.000000     2.000000     3.000000   \n",
       "50%       1.000000     2.000000     2.000000     3.000000     4.000000   \n",
       "75%       1.000000     3.000000     3.000000     4.000000     6.000000   \n",
       "max       7.000000     9.000000     9.000000     9.000000     9.000000   \n",
       "\n",
       "               V16          V17          V18          V19          V20  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      1.484525     3.307269     4.592038     1.898799     0.403278   \n",
       "std       1.645968     1.723377     2.279839     1.814406     0.786792   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     2.000000     3.000000     0.000000     0.000000   \n",
       "50%       1.000000     3.000000     5.000000     2.000000     0.000000   \n",
       "75%       2.000000     4.000000     6.000000     3.000000     1.000000   \n",
       "max       9.000000     9.000000     9.000000     9.000000     5.000000   \n",
       "\n",
       "               V21          V22          V23          V24          V25  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      0.545714     2.877113     2.226532     2.291183     1.650682   \n",
       "std       1.106349     1.846703     1.748025     1.684008     1.742410   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     2.000000     1.000000     1.000000     0.000000   \n",
       "50%       0.000000     3.000000     2.000000     2.000000     1.000000   \n",
       "75%       1.000000     4.000000     3.000000     3.000000     2.000000   \n",
       "max       9.000000     9.000000     9.000000     9.000000     9.000000   \n",
       "\n",
       "               V26          V27          V28          V29          V30  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      1.595093     2.204744     3.742211     1.068214     4.187742   \n",
       "std       1.321487     1.534163     1.944900     1.298229     3.093127   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     1.000000     2.000000     0.000000     2.000000   \n",
       "50%       2.000000     2.000000     4.000000     1.000000     4.000000   \n",
       "75%       2.000000     3.000000     5.000000     2.000000     7.000000   \n",
       "max       9.000000     9.000000     9.000000     9.000000     9.000000   \n",
       "\n",
       "               V31          V32          V33          V34          V35  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      4.819487     6.022501     1.335980     1.956730     6.254327   \n",
       "std       3.093541     1.543980     1.213627     1.596842     2.000374   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     5.000000     0.000000     0.000000     5.000000   \n",
       "50%       5.000000     6.000000     1.000000     2.000000     7.000000   \n",
       "75%       7.000000     7.000000     2.000000     3.000000     8.000000   \n",
       "max       9.000000     9.000000     9.000000     9.000000     9.000000   \n",
       "\n",
       "               V36          V37          V38          V39          V40  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      2.750662     2.577072     3.505498     2.739462     0.808491   \n",
       "std       2.002960     2.073125     1.871365     1.950625     1.173771   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     1.000000     2.000000     1.000000     0.000000   \n",
       "50%       2.000000     2.000000     4.000000     3.000000     0.000000   \n",
       "75%       4.000000     4.000000     5.000000     4.000000     1.000000   \n",
       "max       9.000000     9.000000     9.000000     9.000000     9.000000   \n",
       "\n",
       "               V41         V42          V43          V44          V45  \\\n",
       "count  9822.000000  9822.00000  9822.000000  9822.000000  9822.000000   \n",
       "mean      0.208002     3.80452     4.260334     0.764915     0.038892   \n",
       "std       0.561832     1.33093     1.998913     0.956555     0.356924   \n",
       "min       0.000000     0.00000     1.000000     0.000000     0.000000   \n",
       "25%       0.000000     3.00000     3.000000     0.000000     0.000000   \n",
       "50%       0.000000     4.00000     4.000000     0.000000     0.000000   \n",
       "75%       0.000000     4.00000     6.000000     2.000000     0.000000   \n",
       "max       9.000000     9.00000     8.000000     3.000000     6.000000   \n",
       "\n",
       "               V46          V47          V48          V49          V50  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      0.073712     2.956424     0.054877     0.170841     0.008858   \n",
       "std       0.507818     2.921736     0.566108     0.888518     0.237556   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     5.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     6.000000     0.000000     0.000000     0.000000   \n",
       "max       4.000000     9.000000     7.000000     7.000000     9.000000   \n",
       "\n",
       "               V51          V52          V53          V54          V55  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      0.019344     0.093565     0.011505     0.215027     0.202301   \n",
       "std       0.200885     0.604350     0.215408     0.810899     0.910574   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       5.000000     7.000000     6.000000     6.000000     9.000000   \n",
       "\n",
       "               V56          V57          V58          V59          V60  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      0.011505     0.018733     0.023315     1.849420     0.001629   \n",
       "std       0.188699     0.213712     0.375350     1.881271     0.057058   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     2.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     4.000000     0.000000   \n",
       "max       6.000000     3.000000     7.000000     8.000000     3.000000   \n",
       "\n",
       "               V61          V62          V63          V64          V65  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      0.015272     0.025351     0.016697     0.045408     0.400020   \n",
       "std       0.244210     0.157198     0.211487     0.396983     0.492001   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "max       6.000000     1.000000     6.000000     5.000000     2.000000   \n",
       "\n",
       "               V66          V67          V68          V69          V70  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      0.014050     0.021279     0.557218     0.011098     0.040216   \n",
       "std       0.126058     0.144319     0.608575     0.129928     0.223622   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       5.000000     1.000000    12.000000     5.000000     8.000000   \n",
       "\n",
       "               V71          V72          V73          V74          V75  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      0.002240     0.011403     0.034413     0.005192     0.071065   \n",
       "std       0.068402     0.116251     0.249706     0.109954     0.267432   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       4.000000     3.000000     6.000000     6.000000     3.000000   \n",
       "\n",
       "               V76          V77          V78          V79          V80  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      0.079821     0.004582     0.007941     0.004276     0.574018   \n",
       "std       0.384431     0.067535     0.088764     0.071224     0.561255   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "max       8.000000     1.000000     1.000000     2.000000     7.000000   \n",
       "\n",
       "               V81          V82         V83          V84          V85  \\\n",
       "count  9822.000000  9822.000000  9822.00000  9822.000000  9822.000000   \n",
       "mean      0.000916     0.005091     0.03146     0.008450     0.013846   \n",
       "std       0.030258     0.077996     0.20907     0.092647     0.117728   \n",
       "min       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "max       1.000000     2.000000     4.00000     2.000000     2.000000   \n",
       "\n",
       "               V86  \n",
       "count  5822.000000  \n",
       "mean      0.059773  \n",
       "std       0.237087  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V1', dtype('int64'), 40),\n",
       " ('V2', dtype('int64'), 9),\n",
       " ('V3', dtype('int64'), 6),\n",
       " ('V4', dtype('int64'), 6),\n",
       " ('V5', dtype('int64'), 10),\n",
       " ('V6', dtype('int64'), 10),\n",
       " ('V7', dtype('int64'), 10),\n",
       " ('V8', dtype('int64'), 6),\n",
       " ('V9', dtype('int64'), 10),\n",
       " ('V10', dtype('int64'), 10),\n",
       " ('V11', dtype('int64'), 8),\n",
       " ('V12', dtype('int64'), 10),\n",
       " ('V13', dtype('int64'), 10),\n",
       " ('V14', dtype('int64'), 10),\n",
       " ('V15', dtype('int64'), 10),\n",
       " ('V16', dtype('int64'), 10),\n",
       " ('V17', dtype('int64'), 10),\n",
       " ('V18', dtype('int64'), 10),\n",
       " ('V19', dtype('int64'), 10),\n",
       " ('V20', dtype('int64'), 6),\n",
       " ('V21', dtype('int64'), 10),\n",
       " ('V22', dtype('int64'), 10),\n",
       " ('V23', dtype('int64'), 10),\n",
       " ('V24', dtype('int64'), 10),\n",
       " ('V25', dtype('int64'), 10),\n",
       " ('V26', dtype('int64'), 10),\n",
       " ('V27', dtype('int64'), 10),\n",
       " ('V28', dtype('int64'), 10),\n",
       " ('V29', dtype('int64'), 10),\n",
       " ('V30', dtype('int64'), 10),\n",
       " ('V31', dtype('int64'), 10),\n",
       " ('V32', dtype('int64'), 10),\n",
       " ('V33', dtype('int64'), 9),\n",
       " ('V34', dtype('int64'), 10),\n",
       " ('V35', dtype('int64'), 10),\n",
       " ('V36', dtype('int64'), 10),\n",
       " ('V37', dtype('int64'), 10),\n",
       " ('V38', dtype('int64'), 10),\n",
       " ('V39', dtype('int64'), 10),\n",
       " ('V40', dtype('int64'), 10),\n",
       " ('V41', dtype('int64'), 9),\n",
       " ('V42', dtype('int64'), 10),\n",
       " ('V43', dtype('int64'), 8),\n",
       " ('V44', dtype('int64'), 4),\n",
       " ('V45', dtype('int64'), 7),\n",
       " ('V46', dtype('int64'), 5),\n",
       " ('V47', dtype('int64'), 7),\n",
       " ('V48', dtype('int64'), 4),\n",
       " ('V49', dtype('int64'), 6),\n",
       " ('V50', dtype('int64'), 5),\n",
       " ('V51', dtype('int64'), 6),\n",
       " ('V52', dtype('int64'), 6),\n",
       " ('V53', dtype('int64'), 6),\n",
       " ('V54', dtype('int64'), 6),\n",
       " ('V55', dtype('int64'), 10),\n",
       " ('V56', dtype('int64'), 7),\n",
       " ('V57', dtype('int64'), 3),\n",
       " ('V58', dtype('int64'), 5),\n",
       " ('V59', dtype('int64'), 9),\n",
       " ('V60', dtype('int64'), 4),\n",
       " ('V61', dtype('int64'), 7),\n",
       " ('V62', dtype('int64'), 2),\n",
       " ('V63', dtype('int64'), 7),\n",
       " ('V64', dtype('int64'), 5),\n",
       " ('V65', dtype('int64'), 3),\n",
       " ('V66', dtype('int64'), 3),\n",
       " ('V67', dtype('int64'), 2),\n",
       " ('V68', dtype('int64'), 9),\n",
       " ('V69', dtype('int64'), 6),\n",
       " ('V70', dtype('int64'), 5),\n",
       " ('V71', dtype('int64'), 5),\n",
       " ('V72', dtype('int64'), 4),\n",
       " ('V73', dtype('int64'), 7),\n",
       " ('V74', dtype('int64'), 6),\n",
       " ('V75', dtype('int64'), 4),\n",
       " ('V76', dtype('int64'), 7),\n",
       " ('V77', dtype('int64'), 2),\n",
       " ('V78', dtype('int64'), 2),\n",
       " ('V79', dtype('int64'), 3),\n",
       " ('V80', dtype('int64'), 8),\n",
       " ('V81', dtype('int64'), 2),\n",
       " ('V82', dtype('int64'), 3),\n",
       " ('V83', dtype('int64'), 5),\n",
       " ('V84', dtype('int64'), 3),\n",
       " ('V85', dtype('int64'), 3),\n",
       " ('V86', dtype('float64'), 2),\n",
       " ('data', dtype('O'), 2)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(bd_all.columns,bd_all.dtypes,bd_all.nunique())) # gives the type and\n",
    "#the number of unique values present for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33 37  9 40 23 39 11 10 41 38 22 13 31 34 24  8  7  3 36 25 20 12 35 30\n",
      " 29 32  1 26  2  4 16  5 21  6 18 27 28 17 15 19]\n",
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33    1401\n",
       "38     569\n",
       "8      546\n",
       "39     542\n",
       "9      460\n",
       "3      433\n",
       "23     376\n",
       "36     373\n",
       "35     362\n",
       "41     355\n",
       "34     325\n",
       "24     324\n",
       "31     318\n",
       "13     302\n",
       "11     286\n",
       "10     271\n",
       "32     234\n",
       "37     233\n",
       "1      218\n",
       "6      209\n",
       "12     194\n",
       "30     190\n",
       "22     169\n",
       "2      148\n",
       "29     139\n",
       "40     137\n",
       "25     129\n",
       "4       90\n",
       "26      79\n",
       "27      77\n",
       "7       72\n",
       "5       70\n",
       "20      42\n",
       "28      41\n",
       "21      29\n",
       "18      27\n",
       "16      25\n",
       "17      13\n",
       "15       7\n",
       "19       7\n",
       "Name: V1, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bd_all['V1'].unique()) # gives the unique values in the column\n",
    "print(bd_all['V1'].nunique()) # gives the number of unique values\n",
    "bd_all['V1'].value_counts() # gives counts of each unique value in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars=bd_all.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['data'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 87)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1        int64\n",
       "V2        int64\n",
       "V3        int64\n",
       "V4        int64\n",
       "V5        int64\n",
       "V6        int64\n",
       "V7        int64\n",
       "V8        int64\n",
       "V9        int64\n",
       "V10       int64\n",
       "V11       int64\n",
       "V12       int64\n",
       "V13       int64\n",
       "V14       int64\n",
       "V15       int64\n",
       "V16       int64\n",
       "V17       int64\n",
       "V18       int64\n",
       "V19       int64\n",
       "V20       int64\n",
       "V21       int64\n",
       "V22       int64\n",
       "V23       int64\n",
       "V24       int64\n",
       "V25       int64\n",
       "V26       int64\n",
       "V27       int64\n",
       "V28       int64\n",
       "V29       int64\n",
       "V30       int64\n",
       "V31       int64\n",
       "V32       int64\n",
       "V33       int64\n",
       "V34       int64\n",
       "V35       int64\n",
       "V36       int64\n",
       "V37       int64\n",
       "V38       int64\n",
       "V39       int64\n",
       "V40       int64\n",
       "V41       int64\n",
       "V42       int64\n",
       "V43       int64\n",
       "V44       int64\n",
       "V45       int64\n",
       "V46       int64\n",
       "V47       int64\n",
       "V48       int64\n",
       "V49       int64\n",
       "V50       int64\n",
       "V51       int64\n",
       "V52       int64\n",
       "V53       int64\n",
       "V54       int64\n",
       "V55       int64\n",
       "V56       int64\n",
       "V57       int64\n",
       "V58       int64\n",
       "V59       int64\n",
       "V60       int64\n",
       "V61       int64\n",
       "V62       int64\n",
       "V63       int64\n",
       "V64       int64\n",
       "V65       int64\n",
       "V66       int64\n",
       "V67       int64\n",
       "V68       int64\n",
       "V69       int64\n",
       "V70       int64\n",
       "V71       int64\n",
       "V72       int64\n",
       "V73       int64\n",
       "V74       int64\n",
       "V75       int64\n",
       "V76       int64\n",
       "V77       int64\n",
       "V78       int64\n",
       "V79       int64\n",
       "V80       int64\n",
       "V81       int64\n",
       "V82       int64\n",
       "V83       int64\n",
       "V84       int64\n",
       "V85       int64\n",
       "V86     float64\n",
       "data     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5474\n",
       "1.0     348\n",
       "Name: V86, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all['V86'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V1', dtype('int64'), 40),\n",
       " ('V2', dtype('int64'), 9),\n",
       " ('V3', dtype('int64'), 6),\n",
       " ('V4', dtype('int64'), 6),\n",
       " ('V5', dtype('int64'), 10),\n",
       " ('V6', dtype('int64'), 10),\n",
       " ('V7', dtype('int64'), 10),\n",
       " ('V8', dtype('int64'), 6),\n",
       " ('V9', dtype('int64'), 10),\n",
       " ('V10', dtype('int64'), 10),\n",
       " ('V11', dtype('int64'), 8),\n",
       " ('V12', dtype('int64'), 10),\n",
       " ('V13', dtype('int64'), 10),\n",
       " ('V14', dtype('int64'), 10),\n",
       " ('V15', dtype('int64'), 10),\n",
       " ('V16', dtype('int64'), 10),\n",
       " ('V17', dtype('int64'), 10),\n",
       " ('V18', dtype('int64'), 10),\n",
       " ('V19', dtype('int64'), 10),\n",
       " ('V20', dtype('int64'), 6),\n",
       " ('V21', dtype('int64'), 10),\n",
       " ('V22', dtype('int64'), 10),\n",
       " ('V23', dtype('int64'), 10),\n",
       " ('V24', dtype('int64'), 10),\n",
       " ('V25', dtype('int64'), 10),\n",
       " ('V26', dtype('int64'), 10),\n",
       " ('V27', dtype('int64'), 10),\n",
       " ('V28', dtype('int64'), 10),\n",
       " ('V29', dtype('int64'), 10),\n",
       " ('V30', dtype('int64'), 10),\n",
       " ('V31', dtype('int64'), 10),\n",
       " ('V32', dtype('int64'), 10),\n",
       " ('V33', dtype('int64'), 9),\n",
       " ('V34', dtype('int64'), 10),\n",
       " ('V35', dtype('int64'), 10),\n",
       " ('V36', dtype('int64'), 10),\n",
       " ('V37', dtype('int64'), 10),\n",
       " ('V38', dtype('int64'), 10),\n",
       " ('V39', dtype('int64'), 10),\n",
       " ('V40', dtype('int64'), 10),\n",
       " ('V41', dtype('int64'), 9),\n",
       " ('V42', dtype('int64'), 10),\n",
       " ('V43', dtype('int64'), 8),\n",
       " ('V44', dtype('int64'), 4),\n",
       " ('V45', dtype('int64'), 7),\n",
       " ('V46', dtype('int64'), 5),\n",
       " ('V47', dtype('int64'), 7),\n",
       " ('V48', dtype('int64'), 4),\n",
       " ('V49', dtype('int64'), 6),\n",
       " ('V50', dtype('int64'), 5),\n",
       " ('V51', dtype('int64'), 6),\n",
       " ('V52', dtype('int64'), 6),\n",
       " ('V53', dtype('int64'), 6),\n",
       " ('V54', dtype('int64'), 6),\n",
       " ('V55', dtype('int64'), 10),\n",
       " ('V56', dtype('int64'), 7),\n",
       " ('V57', dtype('int64'), 3),\n",
       " ('V58', dtype('int64'), 5),\n",
       " ('V59', dtype('int64'), 9),\n",
       " ('V60', dtype('int64'), 4),\n",
       " ('V61', dtype('int64'), 7),\n",
       " ('V62', dtype('int64'), 2),\n",
       " ('V63', dtype('int64'), 7),\n",
       " ('V64', dtype('int64'), 5),\n",
       " ('V65', dtype('int64'), 3),\n",
       " ('V66', dtype('int64'), 3),\n",
       " ('V67', dtype('int64'), 2),\n",
       " ('V68', dtype('int64'), 9),\n",
       " ('V69', dtype('int64'), 6),\n",
       " ('V70', dtype('int64'), 5),\n",
       " ('V71', dtype('int64'), 5),\n",
       " ('V72', dtype('int64'), 4),\n",
       " ('V73', dtype('int64'), 7),\n",
       " ('V74', dtype('int64'), 6),\n",
       " ('V75', dtype('int64'), 4),\n",
       " ('V76', dtype('int64'), 7),\n",
       " ('V77', dtype('int64'), 2),\n",
       " ('V78', dtype('int64'), 2),\n",
       " ('V79', dtype('int64'), 3),\n",
       " ('V80', dtype('int64'), 8),\n",
       " ('V81', dtype('int64'), 2),\n",
       " ('V82', dtype('int64'), 3),\n",
       " ('V83', dtype('int64'), 5),\n",
       " ('V84', dtype('int64'), 3),\n",
       " ('V85', dtype('int64'), 3),\n",
       " ('V86', dtype('float64'), 2),\n",
       " ('data', dtype('O'), 2)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(bd_all.columns,bd_all.dtypes,bd_all.nunique())) # gives the type and\n",
    "#the number of unique values present for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33 37  9 40 23 39 11 10 41 38 22 13 31 34 24  8  7  3 36 25 20 12 35 30\n",
      " 29 32  1 26  2  4 16  5 21  6 18 27 28 17 15 19]\n",
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33    1401\n",
       "38     569\n",
       "8      546\n",
       "39     542\n",
       "9      460\n",
       "3      433\n",
       "23     376\n",
       "36     373\n",
       "35     362\n",
       "41     355\n",
       "34     325\n",
       "24     324\n",
       "31     318\n",
       "13     302\n",
       "11     286\n",
       "10     271\n",
       "32     234\n",
       "37     233\n",
       "1      218\n",
       "6      209\n",
       "12     194\n",
       "30     190\n",
       "22     169\n",
       "2      148\n",
       "29     139\n",
       "40     137\n",
       "25     129\n",
       "4       90\n",
       "26      79\n",
       "27      77\n",
       "7       72\n",
       "5       70\n",
       "20      42\n",
       "28      41\n",
       "21      29\n",
       "18      27\n",
       "16      25\n",
       "17      13\n",
       "15       7\n",
       "19       7\n",
       "Name: V1, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bd_all['V1'].unique()) # gives the unique values in the column\n",
    "print(bd_all['V1'].nunique()) # gives the number of unique values\n",
    "bd_all['V1'].value_counts() # gives counts of each unique value in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9822"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all['V1'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33    1401\n",
       "38     569\n",
       "8      546\n",
       "39     542\n",
       "9      460\n",
       "3      433\n",
       "23     376\n",
       "36     373\n",
       "35     362\n",
       "41     355\n",
       "34     325\n",
       "24     324\n",
       "31     318\n",
       "13     302\n",
       "11     286\n",
       "10     271\n",
       "32     234\n",
       "37     233\n",
       "1      218\n",
       "6      209\n",
       "12     194\n",
       "30     190\n",
       "22     169\n",
       "2      148\n",
       "29     139\n",
       "40     137\n",
       "25     129\n",
       "4       90\n",
       "26      79\n",
       "27      77\n",
       "7       72\n",
       "5       70\n",
       "20      42\n",
       "28      41\n",
       "21      29\n",
       "18      27\n",
       "16      25\n",
       "17      13\n",
       "15       7\n",
       "19       7\n",
       "Name: V1, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all[\"V1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_all[\"V1\"]=bd_all[\"V1\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_all[\"V1_33\"]=np.where(bd_all[\"V1\"]==\"33\",1,0)\n",
    "bd_all[\"V1_38\"]=np.where(bd_all[\"V1\"]==\"38\",1,0)\n",
    "bd_all[\"V1_8\"]=np.where(bd_all[\"V1\"]==\"8\",1,0)\n",
    "bd_all[\"V1_39\"]=np.where(bd_all[\"V1\"]==\"39\",1,0)\n",
    "bd_all[\"V1_9\"]=np.where(bd_all[\"V1\"]==\"9\",1,0)\n",
    "bd_all[\"V1_3\"]=np.where(bd_all[\"V1\"]==\"3\",1,0)\n",
    "bd_all[\"V1_23\"]=np.where(bd_all[\"V1\"]==\"23\",1,0)\n",
    "bd_all[\"V1_36\"]=np.where(bd_all[\"V1\"]==\"36\",1,0)\n",
    "bd_all[\"V1_35\"]=np.where(bd_all[\"V1\"]==\"35\",1,0)\n",
    "bd_all[\"V1_41\"]=np.where(bd_all[\"V1\"]==\"41\",1,0)\n",
    "bd_all[\"V1_34\"]=np.where(bd_all[\"V1\"]==\"34\",1,0)\n",
    "bd_all[\"V1_24\"]=np.where(bd_all[\"V1\"]==\"24\",1,0)\n",
    "bd_all[\"V1_31\"]=np.where(bd_all[\"V1\"]==\"31\",1,0)\n",
    "bd_all[\"V1_13\"]=np.where(bd_all[\"V1\"]==\"13\",1,0)\n",
    "bd_all[\"V1_11\"]=np.where(bd_all[\"V1\"]==\"11\",1,0)\n",
    "bd_all[\"V1_10\"]=np.where(bd_all[\"V1\"]==\"10\",1,0)\n",
    "bd_all[\"V1_32\"]=np.where(bd_all[\"V1\"]==\"32\",1,0)\n",
    "bd_all[\"V1_37\"]=np.where(bd_all[\"V1\"]==\"37\",1,0)\n",
    "bd_all[\"V1_1\"]=np.where(bd_all[\"V1\"]==\"1\",1,0)\n",
    "bd_all[\"V1_6\"]=np.where(bd_all[\"V1\"]==\"6\",1,0)\n",
    "bd_all[\"V1_12\"]=np.where(bd_all[\"V1\"]==\"12\",1,0)\n",
    "bd_all[\"V1_30\"]=np.where(bd_all[\"V1\"]==\"30\",1,0)\n",
    "bd_all[\"V1_22\"]=np.where(bd_all[\"V1\"]==\"22\",1,0)\n",
    "bd_all[\"V1_2\"]=np.where(bd_all[\"V1\"]==\"2\",1,0)\n",
    "bd_all[\"V1_29\"]=np.where(bd_all[\"V1\"]==\"29\",1,0)\n",
    "bd_all[\"V1_40\"]=np.where(bd_all[\"V1\"]==\"40\",1,0)\n",
    "bd_all[\"V1_25\"]=np.where(bd_all[\"V1\"]==\"25\",1,0)\n",
    "bd_all[\"V1_4\"]=np.where(bd_all[\"V1\"]==\"4\",1,0)\n",
    "bd_all[\"V1_26\"]=np.where(bd_all[\"V1\"]==\"26\",1,0)\n",
    "bd_all[\"V1_27\"]=np.where(bd_all[\"V1\"]==\"27\",1,0)\n",
    "bd_all[\"V1_7\"]=np.where(bd_all[\"V1\"]==\"7\",1,0)\n",
    "bd_all[\"V1_5\"]=np.where(bd_all[\"V1\"]==\"5\",1,0)\n",
    "bd_all[\"V1_20\"]=np.where(bd_all[\"V1\"]==\"20\",1,0)\n",
    "bd_all[\"V1_28\"]=np.where(bd_all[\"V1\"]==\"28\",1,0)\n",
    "bd_all[\"V1_21\"]=np.where(bd_all[\"V1\"]==\"21\",1,0)\n",
    "bd_all[\"V1_18\"]=np.where(bd_all[\"V1\"]==\"18\",1,0)\n",
    "bd_all[\"V1_16\"]=np.where(bd_all[\"V1\"]==\"16\",1,0)\n",
    "bd_all[\"V1_17\"]=np.where(bd_all[\"V1\"]==\"17\",1,0)\n",
    "bd_all[\"V1_15\"]=np.where(bd_all[\"V1\"]==\"15\",1,0)\n",
    "bd_all[\"V1_19\"]=np.where(bd_all[\"V1\"]==\"19\",1,0)\n",
    "\n",
    "bd_all=bd_all.drop([\"V1\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 126)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_all=bd_all.drop([\"V1_19\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 125)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>V38</th>\n",
       "      <th>V39</th>\n",
       "      <th>V40</th>\n",
       "      <th>V41</th>\n",
       "      <th>V42</th>\n",
       "      <th>V43</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V46</th>\n",
       "      <th>V47</th>\n",
       "      <th>V48</th>\n",
       "      <th>V49</th>\n",
       "      <th>V50</th>\n",
       "      <th>V51</th>\n",
       "      <th>V52</th>\n",
       "      <th>V53</th>\n",
       "      <th>V54</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "      <th>V65</th>\n",
       "      <th>V66</th>\n",
       "      <th>V67</th>\n",
       "      <th>V68</th>\n",
       "      <th>V69</th>\n",
       "      <th>V70</th>\n",
       "      <th>V71</th>\n",
       "      <th>V72</th>\n",
       "      <th>V73</th>\n",
       "      <th>V74</th>\n",
       "      <th>V75</th>\n",
       "      <th>V76</th>\n",
       "      <th>V77</th>\n",
       "      <th>V78</th>\n",
       "      <th>V79</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "      <th>data</th>\n",
       "      <th>V1_33</th>\n",
       "      <th>V1_38</th>\n",
       "      <th>V1_8</th>\n",
       "      <th>V1_39</th>\n",
       "      <th>V1_9</th>\n",
       "      <th>V1_3</th>\n",
       "      <th>V1_23</th>\n",
       "      <th>V1_36</th>\n",
       "      <th>V1_35</th>\n",
       "      <th>V1_41</th>\n",
       "      <th>V1_34</th>\n",
       "      <th>V1_24</th>\n",
       "      <th>V1_31</th>\n",
       "      <th>V1_13</th>\n",
       "      <th>V1_11</th>\n",
       "      <th>V1_10</th>\n",
       "      <th>V1_32</th>\n",
       "      <th>V1_37</th>\n",
       "      <th>V1_1</th>\n",
       "      <th>V1_6</th>\n",
       "      <th>V1_12</th>\n",
       "      <th>V1_30</th>\n",
       "      <th>V1_22</th>\n",
       "      <th>V1_2</th>\n",
       "      <th>V1_29</th>\n",
       "      <th>V1_40</th>\n",
       "      <th>V1_25</th>\n",
       "      <th>V1_4</th>\n",
       "      <th>V1_26</th>\n",
       "      <th>V1_27</th>\n",
       "      <th>V1_7</th>\n",
       "      <th>V1_5</th>\n",
       "      <th>V1_20</th>\n",
       "      <th>V1_28</th>\n",
       "      <th>V1_21</th>\n",
       "      <th>V1_18</th>\n",
       "      <th>V1_16</th>\n",
       "      <th>V1_17</th>\n",
       "      <th>V1_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V2  V3  V4  V5  V6  V7  V8  V9  V10  V11  V12  V13  V14  V15  V16  V17  \\\n",
       "0   1   3   2   8   0   5   1   3    7    0    2    1    2    6    1    2   \n",
       "1   1   2   2   8   1   4   1   4    6    2    2    0    4    5    0    5   \n",
       "2   1   2   2   8   0   4   2   4    3    2    4    4    4    2    0    5   \n",
       "3   1   3   3   3   2   3   2   4    5    2    2    2    3    4    3    4   \n",
       "4   1   4   2  10   1   4   1   4    7    1    2    2    4    4    5    4   \n",
       "\n",
       "   V18  V19  V20  V21  V22  V23  V24  V25  V26  V27  V28  V29  V30  V31  V32  \\\n",
       "0    7    1    0    1    2    5    2    1    1    2    6    1    1    8    8   \n",
       "1    4    0    0    0    5    0    4    0    2    3    5    0    2    7    7   \n",
       "2    4    0    0    0    7    0    2    0    5    0    4    0    7    2    7   \n",
       "3    2    4    0    0    3    1    2    3    2    1    4    0    5    4    9   \n",
       "4    0    0    5    4    0    0    0    9    0    0    0    0    4    5    6   \n",
       "\n",
       "   V33  V34  V35  V36  V37  V38  V39  V40  V41  V42  V43  V44  V45  V46  V47  \\\n",
       "0    0    1    8    1    0    4    5    0    0    4    3    0    0    0    6   \n",
       "1    1    2    6    3    2    0    5    2    0    5    4    2    0    0    0   \n",
       "2    0    2    9    0    4    5    0    0    0    3    4    2    0    0    6   \n",
       "3    0    0    7    2    1    5    3    0    0    4    4    0    0    0    6   \n",
       "4    2    1    5    4    0    0    9    0    0    6    3    0    0    0    0   \n",
       "\n",
       "   V48  V49  V50  V51  V52  V53  V54  V55  V56  V57  V58  V59  V60  V61  V62  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0    0    5    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0    0    6    0    0    0   \n",
       "\n",
       "   V63  V64  V65  V66  V67  V68  V69  V70  V71  V72  V73  V74  V75  V76  V77  \\\n",
       "0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0   \n",
       "1    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2    0    0    1    0    0    1    0    0    0    0    0    0    0    0    0   \n",
       "3    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   V78  V79  V80  V81  V82  V83  V84  V85  V86   data  V1_33  V1_38  V1_8  \\\n",
       "0    0    0    1    0    0    0    0    0  0.0  train      1      0     0   \n",
       "1    0    0    1    0    0    0    0    0  0.0  train      0      0     0   \n",
       "2    0    0    1    0    0    0    0    0  0.0  train      0      0     0   \n",
       "3    0    0    1    0    0    0    0    0  0.0  train      0      0     0   \n",
       "4    0    0    1    0    0    0    0    0  0.0  train      0      0     0   \n",
       "\n",
       "   V1_39  V1_9  V1_3  V1_23  V1_36  V1_35  V1_41  V1_34  V1_24  V1_31  V1_13  \\\n",
       "0      0     0     0      0      0      0      0      0      0      0      0   \n",
       "1      0     0     0      0      0      0      0      0      0      0      0   \n",
       "2      0     0     0      0      0      0      0      0      0      0      0   \n",
       "3      0     1     0      0      0      0      0      0      0      0      0   \n",
       "4      0     0     0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   V1_11  V1_10  V1_32  V1_37  V1_1  V1_6  V1_12  V1_30  V1_22  V1_2  V1_29  \\\n",
       "0      0      0      0      0     0     0      0      0      0     0      0   \n",
       "1      0      0      0      1     0     0      0      0      0     0      0   \n",
       "2      0      0      0      1     0     0      0      0      0     0      0   \n",
       "3      0      0      0      0     0     0      0      0      0     0      0   \n",
       "4      0      0      0      0     0     0      0      0      0     0      0   \n",
       "\n",
       "   V1_40  V1_25  V1_4  V1_26  V1_27  V1_7  V1_5  V1_20  V1_28  V1_21  V1_18  \\\n",
       "0      0      0     0      0      0     0     0      0      0      0      0   \n",
       "1      0      0     0      0      0     0     0      0      0      0      0   \n",
       "2      0      0     0      0      0     0     0      0      0      0      0   \n",
       "3      0      0     0      0      0     0     0      0      0      0      0   \n",
       "4      1      0     0      0      0     0     0      0      0      0      0   \n",
       "\n",
       "   V1_16  V1_17  V1_15  \n",
       "0      0      0      0  \n",
       "1      0      0      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V2         int64\n",
       "V3         int64\n",
       "V4         int64\n",
       "V5         int64\n",
       "V6         int64\n",
       "V7         int64\n",
       "V8         int64\n",
       "V9         int64\n",
       "V10        int64\n",
       "V11        int64\n",
       "V12        int64\n",
       "V13        int64\n",
       "V14        int64\n",
       "V15        int64\n",
       "V16        int64\n",
       "V17        int64\n",
       "V18        int64\n",
       "V19        int64\n",
       "V20        int64\n",
       "V21        int64\n",
       "V22        int64\n",
       "V23        int64\n",
       "V24        int64\n",
       "V25        int64\n",
       "V26        int64\n",
       "V27        int64\n",
       "V28        int64\n",
       "V29        int64\n",
       "V30        int64\n",
       "V31        int64\n",
       "V32        int64\n",
       "V33        int64\n",
       "V34        int64\n",
       "V35        int64\n",
       "V36        int64\n",
       "V37        int64\n",
       "V38        int64\n",
       "V39        int64\n",
       "V40        int64\n",
       "V41        int64\n",
       "V42        int64\n",
       "V43        int64\n",
       "V44        int64\n",
       "V45        int64\n",
       "V46        int64\n",
       "V47        int64\n",
       "V48        int64\n",
       "V49        int64\n",
       "V50        int64\n",
       "V51        int64\n",
       "V52        int64\n",
       "V53        int64\n",
       "V54        int64\n",
       "V55        int64\n",
       "V56        int64\n",
       "V57        int64\n",
       "V58        int64\n",
       "V59        int64\n",
       "V60        int64\n",
       "V61        int64\n",
       "V62        int64\n",
       "V63        int64\n",
       "V64        int64\n",
       "V65        int64\n",
       "V66        int64\n",
       "V67        int64\n",
       "V68        int64\n",
       "V69        int64\n",
       "V70        int64\n",
       "V71        int64\n",
       "V72        int64\n",
       "V73        int64\n",
       "V74        int64\n",
       "V75        int64\n",
       "V76        int64\n",
       "V77        int64\n",
       "V78        int64\n",
       "V79        int64\n",
       "V80        int64\n",
       "V81        int64\n",
       "V82        int64\n",
       "V83        int64\n",
       "V84        int64\n",
       "V85        int64\n",
       "V86      float64\n",
       "data      object\n",
       "V1_33      int32\n",
       "V1_38      int32\n",
       "V1_8       int32\n",
       "V1_39      int32\n",
       "V1_9       int32\n",
       "V1_3       int32\n",
       "V1_23      int32\n",
       "V1_36      int32\n",
       "V1_35      int32\n",
       "V1_41      int32\n",
       "V1_34      int32\n",
       "V1_24      int32\n",
       "V1_31      int32\n",
       "V1_13      int32\n",
       "V1_11      int32\n",
       "V1_10      int32\n",
       "V1_32      int32\n",
       "V1_37      int32\n",
       "V1_1       int32\n",
       "V1_6       int32\n",
       "V1_12      int32\n",
       "V1_30      int32\n",
       "V1_22      int32\n",
       "V1_2       int32\n",
       "V1_29      int32\n",
       "V1_40      int32\n",
       "V1_25      int32\n",
       "V1_4       int32\n",
       "V1_26      int32\n",
       "V1_27      int32\n",
       "V1_7       int32\n",
       "V1_5       int32\n",
       "V1_20      int32\n",
       "V1_28      int32\n",
       "V1_21      int32\n",
       "V1_18      int32\n",
       "V1_16      int32\n",
       "V1_17      int32\n",
       "V1_15      int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 1 4 5 6]\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    5154\n",
       "2    2409\n",
       "4    1777\n",
       "5     329\n",
       "1     104\n",
       "6      49\n",
       "Name: V4, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bd_all['V4'].unique()) # gives the unique values in the column\n",
    "print(bd_all['V4'].nunique()) # gives the number of unique values\n",
    "bd_all['V4'].value_counts() # gives counts of each unique value in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_all[\"V4\"]=bd_all[\"V4\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_all[\"V4_3\"]=np.where(bd_all[\"V4\"]==\"3\",1,0)\n",
    "bd_all[\"V4_2\"]=np.where(bd_all[\"V4\"]==\"2\",1,0)\n",
    "bd_all[\"V4_4\"]=np.where(bd_all[\"V4\"]==\"4\",1,0)\n",
    "bd_all[\"V4_5\"]=np.where(bd_all[\"V4\"]==\"5\",1,0)\n",
    "bd_all[\"V4_1\"]=np.where(bd_all[\"V4\"]==\"1\",1,0)\n",
    "bd_all[\"V4_6\"]=np.where(bd_all[\"V4\"]==\"6\",1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 131)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_all=bd_all.drop([\"V4_6\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_all=bd_all.drop([\"V4\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 129)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>V38</th>\n",
       "      <th>V39</th>\n",
       "      <th>V40</th>\n",
       "      <th>V41</th>\n",
       "      <th>V42</th>\n",
       "      <th>V43</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V46</th>\n",
       "      <th>V47</th>\n",
       "      <th>V48</th>\n",
       "      <th>V49</th>\n",
       "      <th>V50</th>\n",
       "      <th>V51</th>\n",
       "      <th>V52</th>\n",
       "      <th>V53</th>\n",
       "      <th>V54</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "      <th>V65</th>\n",
       "      <th>V66</th>\n",
       "      <th>V67</th>\n",
       "      <th>V68</th>\n",
       "      <th>V69</th>\n",
       "      <th>V70</th>\n",
       "      <th>V71</th>\n",
       "      <th>V72</th>\n",
       "      <th>V73</th>\n",
       "      <th>V74</th>\n",
       "      <th>V75</th>\n",
       "      <th>V76</th>\n",
       "      <th>V77</th>\n",
       "      <th>V78</th>\n",
       "      <th>V79</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "      <th>data</th>\n",
       "      <th>V1_33</th>\n",
       "      <th>V1_38</th>\n",
       "      <th>V1_8</th>\n",
       "      <th>V1_39</th>\n",
       "      <th>V1_9</th>\n",
       "      <th>V1_3</th>\n",
       "      <th>V1_23</th>\n",
       "      <th>V1_36</th>\n",
       "      <th>V1_35</th>\n",
       "      <th>V1_41</th>\n",
       "      <th>V1_34</th>\n",
       "      <th>V1_24</th>\n",
       "      <th>V1_31</th>\n",
       "      <th>V1_13</th>\n",
       "      <th>V1_11</th>\n",
       "      <th>V1_10</th>\n",
       "      <th>V1_32</th>\n",
       "      <th>V1_37</th>\n",
       "      <th>V1_1</th>\n",
       "      <th>V1_6</th>\n",
       "      <th>V1_12</th>\n",
       "      <th>V1_30</th>\n",
       "      <th>V1_22</th>\n",
       "      <th>V1_2</th>\n",
       "      <th>V1_29</th>\n",
       "      <th>V1_40</th>\n",
       "      <th>V1_25</th>\n",
       "      <th>V1_4</th>\n",
       "      <th>V1_26</th>\n",
       "      <th>V1_27</th>\n",
       "      <th>V1_7</th>\n",
       "      <th>V1_5</th>\n",
       "      <th>V1_20</th>\n",
       "      <th>V1_28</th>\n",
       "      <th>V1_21</th>\n",
       "      <th>V1_18</th>\n",
       "      <th>V1_16</th>\n",
       "      <th>V1_17</th>\n",
       "      <th>V1_15</th>\n",
       "      <th>V4_3</th>\n",
       "      <th>V4_2</th>\n",
       "      <th>V4_4</th>\n",
       "      <th>V4_5</th>\n",
       "      <th>V4_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V2  V3  V5  V6  V7  V8  V9  V10  V11  V12  V13  V14  V15  V16  V17  V18  \\\n",
       "0   1   3   8   0   5   1   3    7    0    2    1    2    6    1    2    7   \n",
       "1   1   2   8   1   4   1   4    6    2    2    0    4    5    0    5    4   \n",
       "2   1   2   8   0   4   2   4    3    2    4    4    4    2    0    5    4   \n",
       "3   1   3   3   2   3   2   4    5    2    2    2    3    4    3    4    2   \n",
       "4   1   4  10   1   4   1   4    7    1    2    2    4    4    5    4    0   \n",
       "\n",
       "   V19  V20  V21  V22  V23  V24  V25  V26  V27  V28  V29  V30  V31  V32  V33  \\\n",
       "0    1    0    1    2    5    2    1    1    2    6    1    1    8    8    0   \n",
       "1    0    0    0    5    0    4    0    2    3    5    0    2    7    7    1   \n",
       "2    0    0    0    7    0    2    0    5    0    4    0    7    2    7    0   \n",
       "3    4    0    0    3    1    2    3    2    1    4    0    5    4    9    0   \n",
       "4    0    5    4    0    0    0    9    0    0    0    0    4    5    6    2   \n",
       "\n",
       "   V34  V35  V36  V37  V38  V39  V40  V41  V42  V43  V44  V45  V46  V47  V48  \\\n",
       "0    1    8    1    0    4    5    0    0    4    3    0    0    0    6    0   \n",
       "1    2    6    3    2    0    5    2    0    5    4    2    0    0    0    0   \n",
       "2    2    9    0    4    5    0    0    0    3    4    2    0    0    6    0   \n",
       "3    0    7    2    1    5    3    0    0    4    4    0    0    0    6    0   \n",
       "4    1    5    4    0    0    9    0    0    6    3    0    0    0    0    0   \n",
       "\n",
       "   V49  V50  V51  V52  V53  V54  V55  V56  V57  V58  V59  V60  V61  V62  V63  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0    5    0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0    6    0    0    0    0   \n",
       "\n",
       "   V64  V65  V66  V67  V68  V69  V70  V71  V72  V73  V74  V75  V76  V77  V78  \\\n",
       "0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0   \n",
       "1    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2    0    1    0    0    1    0    0    0    0    0    0    0    0    0    0   \n",
       "3    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   V79  V80  V81  V82  V83  V84  V85  V86   data  V1_33  V1_38  V1_8  V1_39  \\\n",
       "0    0    1    0    0    0    0    0  0.0  train      1      0     0      0   \n",
       "1    0    1    0    0    0    0    0  0.0  train      0      0     0      0   \n",
       "2    0    1    0    0    0    0    0  0.0  train      0      0     0      0   \n",
       "3    0    1    0    0    0    0    0  0.0  train      0      0     0      0   \n",
       "4    0    1    0    0    0    0    0  0.0  train      0      0     0      0   \n",
       "\n",
       "   V1_9  V1_3  V1_23  V1_36  V1_35  V1_41  V1_34  V1_24  V1_31  V1_13  V1_11  \\\n",
       "0     0     0      0      0      0      0      0      0      0      0      0   \n",
       "1     0     0      0      0      0      0      0      0      0      0      0   \n",
       "2     0     0      0      0      0      0      0      0      0      0      0   \n",
       "3     1     0      0      0      0      0      0      0      0      0      0   \n",
       "4     0     0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   V1_10  V1_32  V1_37  V1_1  V1_6  V1_12  V1_30  V1_22  V1_2  V1_29  V1_40  \\\n",
       "0      0      0      0     0     0      0      0      0     0      0      0   \n",
       "1      0      0      1     0     0      0      0      0     0      0      0   \n",
       "2      0      0      1     0     0      0      0      0     0      0      0   \n",
       "3      0      0      0     0     0      0      0      0     0      0      0   \n",
       "4      0      0      0     0     0      0      0      0     0      0      1   \n",
       "\n",
       "   V1_25  V1_4  V1_26  V1_27  V1_7  V1_5  V1_20  V1_28  V1_21  V1_18  V1_16  \\\n",
       "0      0     0      0      0     0     0      0      0      0      0      0   \n",
       "1      0     0      0      0     0     0      0      0      0      0      0   \n",
       "2      0     0      0      0     0     0      0      0      0      0      0   \n",
       "3      0     0      0      0     0     0      0      0      0      0      0   \n",
       "4      0     0      0      0     0     0      0      0      0      0      0   \n",
       "\n",
       "   V1_17  V1_15  V4_3  V4_2  V4_4  V4_5  V4_1  \n",
       "0      0      0     0     1     0     0     0  \n",
       "1      0      0     0     1     0     0     0  \n",
       "2      0      0     0     1     0     0     0  \n",
       "3      0      0     1     0     0     0     0  \n",
       "4      0      0     0     1     0     0     0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  3 10  5  9  7  2  1  6  4]\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8     2694\n",
       "3     1513\n",
       "9     1111\n",
       "1      959\n",
       "5      940\n",
       "7      881\n",
       "2      827\n",
       "10     492\n",
       "6      326\n",
       "4       79\n",
       "Name: V5, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bd_all['V5'].unique()) # gives the unique values in the column\n",
    "print(bd_all['V5'].nunique()) # gives the number of unique values\n",
    "bd_all['V5'].value_counts() # gives counts of each unique value in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_all[\"V5\"]=bd_all[\"V5\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_all[\"V5_8\"]=np.where(bd_all[\"V5\"]==\"8\",1,0)\n",
    "bd_all[\"V5_3\"]=np.where(bd_all[\"V5\"]==\"3\",1,0)\n",
    "bd_all[\"V5_9\"]=np.where(bd_all[\"V5\"]==\"9\",1,0)\n",
    "bd_all[\"V5_1\"]=np.where(bd_all[\"V5\"]==\"1\",1,0)\n",
    "bd_all[\"V5_5\"]=np.where(bd_all[\"V5\"]==\"5\",1,0)\n",
    "bd_all[\"V5_7\"]=np.where(bd_all[\"V5\"]==\"7\",1,0)\n",
    "bd_all[\"V5_2\"]=np.where(bd_all[\"V5\"]==\"2\",1,0)\n",
    "bd_all[\"V5_10\"]=np.where(bd_all[\"V5\"]==\"10\",1,0)\n",
    "bd_all[\"V5_6\"]=np.where(bd_all[\"V5\"]==\"6\",1,0)\n",
    "bd_all[\"V5_4\"]=np.where(bd_all[\"V5\"]==\"4\",1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 139)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_all=bd_all.drop([\"V5_4\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_all=bd_all.drop([\"V5\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 137)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 6 5 9 7 8]\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    5420\n",
       "1    2744\n",
       "2    1213\n",
       "3     243\n",
       "4     123\n",
       "5      30\n",
       "6      25\n",
       "7      11\n",
       "9      10\n",
       "8       3\n",
       "Name: V6, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bd_all['V6'].unique()) # gives the unique values in the column\n",
    "print(bd_all['V6'].nunique()) # gives the number of unique values\n",
    "bd_all['V6'].value_counts() # gives counts of each unique value in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_all[\"V6\"]=bd_all[\"V6\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_all[\"V6_0\"]=np.where(bd_all[\"V6\"]==\"0\",1,0)\n",
    "bd_all[\"V6_1\"]=np.where(bd_all[\"V6\"]==\"1\",1,0)\n",
    "bd_all[\"V6_2\"]=np.where(bd_all[\"V6\"]==\"2\",1,0)\n",
    "bd_all[\"V6_3\"]=np.where(bd_all[\"V6\"]==\"3\",1,0)\n",
    "bd_all[\"V6_4\"]=np.where(bd_all[\"V6\"]==\"4\",1,0)\n",
    "bd_all[\"V6_5\"]=np.where(bd_all[\"V6\"]==\"5\",1,0)\n",
    "bd_all[\"V6_6\"]=np.where(bd_all[\"V6\"]==\"6\",1,0)\n",
    "bd_all[\"V6_7\"]=np.where(bd_all[\"V6\"]==\"7\",1,0)\n",
    "bd_all[\"V6_9\"]=np.where(bd_all[\"V6\"]==\"9\",1,0)\n",
    "bd_all[\"V6_8\"]=np.where(bd_all[\"V6\"]==\"8\",1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 147)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_all=bd_all.drop([\"V6_8\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_all=bd_all.drop([\"V6\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 145)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 3]\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    5903\n",
       "2    3562\n",
       "1     341\n",
       "3      16\n",
       "Name: V44, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bd_all['V44'].unique()) # gives the unique values in the column\n",
    "print(bd_all['V44'].nunique()) # gives the number of unique values\n",
    "bd_all['V44'].value_counts() # gives counts of each unique value in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5474\n",
       "1.0     348\n",
       "Name: V86, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all['V86'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5474\n",
       "1     348\n",
       "Name: V86, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_train['V86'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31',\n",
       "       'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41',\n",
       "       'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51',\n",
       "       'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61',\n",
       "       'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71',\n",
       "       'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81',\n",
       "       'V82', 'V83', 'V84', 'V85', 'V86', 'data'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     8915\n",
       "2      821\n",
       "3       64\n",
       "7        8\n",
       "4        4\n",
       "6        3\n",
       "5        3\n",
       "10       2\n",
       "8        2\n",
       "Name: V2, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all['V2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    4513\n",
       "2    3616\n",
       "4    1132\n",
       "1     452\n",
       "5     106\n",
       "6       3\n",
       "Name: V3, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all['V3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['V2','V3','V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85']:\n",
    "    \n",
    "    temp=pd.get_dummies(bd_all[col],prefix=col,drop_first=True)\n",
    "    bd_all=pd.concat([temp,bd_all],1)\n",
    "    bd_all.drop([col],1,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "3995    0\n",
       "3996    0\n",
       "3997    0\n",
       "3998    1\n",
       "3999    0\n",
       "Name: V3_3, Length: 9822, dtype: uint8"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all[\"V3_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V85_1    uint8\n",
       "V85_2    uint8\n",
       "V84_1    uint8\n",
       "V84_2    uint8\n",
       "V83_1    uint8\n",
       "         ...  \n",
       "V6_4     int32\n",
       "V6_5     int32\n",
       "V6_6     int32\n",
       "V6_7     int32\n",
       "V6_9     int32\n",
       "Length: 567, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 567)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_train=bd_all[bd_all['data']=='train'] # Select only those rows where the data column has the value 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bd_train['data'] # Remove the data column from bd_train data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_test=bd_all[bd_all['data']=='test'] # Select only those rows where the data column has the value 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "bd_test.drop(['V86','data'],axis=1,inplace=True) # Remove the data and Interest.Rate column from bd_test data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 567)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5822, 566)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 565)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bd_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V85_1    0\n",
       "V85_2    0\n",
       "V84_1    0\n",
       "V84_2    0\n",
       "V83_1    0\n",
       "        ..\n",
       "V6_4     0\n",
       "V6_5     0\n",
       "V6_6     0\n",
       "V6_7     0\n",
       "V6_9     0\n",
       "Length: 566, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_train.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V85_1    0\n",
       "V85_2    0\n",
       "V84_1    0\n",
       "V84_2    0\n",
       "V83_1    0\n",
       "        ..\n",
       "V6_4     0\n",
       "V6_5     0\n",
       "V6_6     0\n",
       "V6_7     0\n",
       "V6_9     0\n",
       "Length: 565, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_test.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_train1, bd_test1 = train_test_split(bd_train, test_size = 0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1=bd_train1.drop(['V86'],1)\n",
    "y_train1=bd_train1['V86']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1=bd_test1.drop(['V86'],1)\n",
    "y_test1=bd_test1['V86']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train1.reset_index(drop=True,inplace=True)\n",
    "# y_train1.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4657, 565)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4657,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1165, 565)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1165,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'class_weight':['balanced'],\n",
    "        'n_jobs':[-1],\n",
    "'penalty':['l1','l2'],\n",
    "'C':np.linspace(1,1000,10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': ['balanced'],\n",
       " 'n_jobs': [-1],\n",
       " 'penalty': ['l1', 'l2'],\n",
       " 'C': array([   1.,  112.,  223.,  334.,  445.,  556.,  667.,  778.,  889.,\n",
       "        1000.])}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(model,param_grid=params,cv=5,scoring=\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': array([   1.,  112.,  223.,  334.,  445.,  556.,  667.,  778.,  889.,\n",
       "       1000.]),\n",
       "                         'class_weight': ['balanced'], 'n_jobs': [-1],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_train1 , y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Mr. Jarvis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=-1, penalty='l1',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6813761467889908"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test1 , logr.predict(x_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_score=pd.Series(list(zip(*logr.predict_proba(x_train1)))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.396957\n",
       "1       0.267338\n",
       "2       0.113860\n",
       "3       0.045411\n",
       "4       0.159665\n",
       "          ...   \n",
       "4652    0.050598\n",
       "4653    0.238406\n",
       "4654    0.041890\n",
       "4655    0.303063\n",
       "4656    0.159888\n",
       "Length: 4657, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs=np.linspace(0,1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS_cut=[]\n",
    "for cutoff in cutoffs:\n",
    "    predicted=pd.Series([0]*len(y_train1))\n",
    "    predicted[prob_score>cutoff]=1\n",
    "    df=pd.DataFrame(list(zip(y_train1,predicted)),columns=[\"real\",\"predicted\"])\n",
    "    TP=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==1) ])\n",
    "    FP=len(df[(df[\"real\"]==0) &(df[\"predicted\"]==1) ])\n",
    "    TN=len(df[(df[\"real\"]==0) &(df[\"predicted\"]==0) ])\n",
    "    FN=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==0) ])\n",
    "    P=TP+FN\n",
    "    N=TN+FP\n",
    "    KS=(TP/P)-(FP/N)\n",
    "    KS_cut.append(KS)\n",
    "\n",
    "cutoff_data=pd.DataFrame(list(zip(cutoffs,KS_cut)),columns=[\"cutoff\",\"KS\"])\n",
    "\n",
    "KS_cutoff=cutoff_data[cutoff_data[\"KS\"]==cutoff_data[\"KS\"].max()][\"cutoff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix :\n",
      " \n",
      "  predicted    0    1\n",
      "real               \n",
      "0.0        857  233\n",
      "1.0         32   43\n"
     ]
    }
   ],
   "source": [
    "# Performance on test data\n",
    "prob_score_test=pd.Series(list(zip(*logr.predict_proba(x_test1)))[1])\n",
    "\n",
    "predicted_test=pd.Series([0]*len(y_test1))\n",
    "predicted_test[prob_score_test>float(KS_cutoff)]=1\n",
    "\n",
    "df_test=pd.DataFrame(list(zip(y_test1,predicted_test)),columns=[\"real\",\"predicted\"])\n",
    "\n",
    "k=pd.crosstab(df_test['real'],df_test[\"predicted\"])\n",
    "print('confusion matrix :\\n \\n ',k)\n",
    "TN=k.iloc[0,0]\n",
    "TP=k.iloc[1,1]\n",
    "FP=k.iloc[0,1]\n",
    "FN=k.iloc[1,0]\n",
    "P=TP+FN\n",
    "N=TN+FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7725321888412017"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of test\n",
    "(TP+TN)/(P+N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5733333333333334"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sensitivity on test\n",
    "TP/P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7862385321100918"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specificity on test\n",
    "TN/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs=np.linspace(0.010,0.99,100)\n",
    "def Fbeta_perf(beta,cutoffs,y_train1,prob_score):\n",
    "    FB_cut=[]\n",
    "    for cutoff in cutoffs:\n",
    "        predicted=pd.Series([0]*len(y_train1))\n",
    "        predicted[prob_score>cutoff]=1\n",
    "        df=pd.DataFrame(list(zip(y_train1,predicted)),columns=[\"real\",\"predicted\"])\n",
    "\n",
    "        TP=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==1) ])\n",
    "        FP=len(df[(df[\"real\"]==0) &(df[\"predicted\"]==1) ])\n",
    "        FN=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==0) ])\n",
    "        P=TP+FN\n",
    "        \n",
    "        \n",
    "        Precision=TP/(TP+FP)\n",
    "        Recall=TP/P\n",
    "        FB=(1+beta**2)*Precision*Recall/((beta**2)*Precision+Recall)\n",
    "        FB_cut.append(FB)\n",
    "\n",
    "    cutoff_data=pd.DataFrame(list(zip(cutoffs,FB_cut)),columns=[\"cutoff\",\"FB\"])\n",
    "\n",
    "    FB_cutoff=cutoff_data[cutoff_data[\"FB\"]==cutoff_data[\"FB\"].max()][\"cutoff\"]\n",
    "\n",
    "    prob_score_test=pd.Series(list(zip(*logr.predict_proba(x_test1)))[1])\n",
    "\n",
    "    predicted_test=pd.Series([0]*len(y_test1))\n",
    "    predicted_test[prob_score_test>float(FB_cutoff)]=1\n",
    "\n",
    "    df_test=pd.DataFrame(list(zip(y_test1,predicted_test)),columns=[\"real\",\"predicted\"])\n",
    "\n",
    "    k=pd.crosstab(df_test['real'],df_test[\"predicted\"])\n",
    "    \n",
    "#print('confusion matrix :\\n \\n ',k)\n",
    "    TN=k.iloc[0,0]\n",
    "    TP=k.iloc[1,1]\n",
    "    FP=k.iloc[0,1]\n",
    "    FN=k.iloc[1,0]\n",
    "    P=TP+FN\n",
    "    N=TN+FP\n",
    "    print('For beta :',beta)\n",
    "    print('Accuracy is :',(TP+TN)/(P+N))\n",
    "    print('Sensitivity is :',(TP/P))\n",
    "    print('Specificity is :',(TN/N))\n",
    "    print('\\n \\n \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For beta : 0.5\n",
      "Accuracy is : 0.8763948497854077\n",
      "Sensitivity is : 0.3333333333333333\n",
      "Specificity is : 0.9137614678899083\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "For beta : 1\n",
      "Accuracy is : 0.8446351931330472\n",
      "Sensitivity is : 0.37333333333333335\n",
      "Specificity is : 0.8770642201834863\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "For beta : 3\n",
      "Accuracy is : 0.7725321888412017\n",
      "Sensitivity is : 0.5733333333333334\n",
      "Specificity is : 0.7862385321100918\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "For beta : 2\n",
      "Accuracy is : 0.7931330472103004\n",
      "Sensitivity is : 0.56\n",
      "Specificity is : 0.8091743119266055\n",
      "\n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Fbeta_perf(0.5,cutoffs,y_train1,prob_score)\n",
    "Fbeta_perf(1,cutoffs,y_train1,prob_score)\n",
    "Fbeta_perf(3,cutoffs,y_train1,prob_score)\n",
    "Fbeta_perf(2,cutoffs,y_train1,prob_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01      , 0.01989899, 0.02979798, 0.03969697, 0.04959596,\n",
       "       0.05949495, 0.06939394, 0.07929293, 0.08919192, 0.09909091,\n",
       "       0.1089899 , 0.11888889, 0.12878788, 0.13868687, 0.14858586,\n",
       "       0.15848485, 0.16838384, 0.17828283, 0.18818182, 0.19808081,\n",
       "       0.2079798 , 0.21787879, 0.22777778, 0.23767677, 0.24757576,\n",
       "       0.25747475, 0.26737374, 0.27727273, 0.28717172, 0.29707071,\n",
       "       0.3069697 , 0.31686869, 0.32676768, 0.33666667, 0.34656566,\n",
       "       0.35646465, 0.36636364, 0.37626263, 0.38616162, 0.39606061,\n",
       "       0.4059596 , 0.41585859, 0.42575758, 0.43565657, 0.44555556,\n",
       "       0.45545455, 0.46535354, 0.47525253, 0.48515152, 0.49505051,\n",
       "       0.50494949, 0.51484848, 0.52474747, 0.53464646, 0.54454545,\n",
       "       0.55444444, 0.56434343, 0.57424242, 0.58414141, 0.5940404 ,\n",
       "       0.60393939, 0.61383838, 0.62373737, 0.63363636, 0.64353535,\n",
       "       0.65343434, 0.66333333, 0.67323232, 0.68313131, 0.6930303 ,\n",
       "       0.70292929, 0.71282828, 0.72272727, 0.73262626, 0.74252525,\n",
       "       0.75242424, 0.76232323, 0.77222222, 0.78212121, 0.7920202 ,\n",
       "       0.80191919, 0.81181818, 0.82171717, 0.83161616, 0.84151515,\n",
       "       0.85141414, 0.86131313, 0.87121212, 0.88111111, 0.8910101 ,\n",
       "       0.90090909, 0.91080808, 0.92070707, 0.93060606, 0.94050505,\n",
       "       0.95040404, 0.96030303, 0.97020202, 0.98010101, 0.99      ])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "train_score=logr.predict_proba(x_train1)[:,1] # the predicted response variablevalues\n",
    "real=y_train1 # the actual response variable values\n",
    "print(logr.classes_) # In order to find the probability of which column is for outcome 1 and which for outcome 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS_all=[]\n",
    "fbeta05_all=[]\n",
    "fbeta5_all=[]\n",
    "fbeta2_all=[]\n",
    "fbeta3_all=[]\n",
    "for cutoff in cutoffs:\n",
    "\n",
    "    predicted=(train_score>cutoff).astype(int)\n",
    "\n",
    "    TP=((predicted==1) & (real==1)).sum()\n",
    "    TN=((predicted==0) & (real==0)).sum()\n",
    "    FP=((predicted==1) & (real==0)).sum()\n",
    "    FN=((predicted==0) & (real==1)).sum()\n",
    "\n",
    "    P=TP+FN\n",
    "    N=TN+FP\n",
    "\n",
    "    KS=(TP/P)-(FP/N)\n",
    "\n",
    "    KS_all.append(KS)\n",
    "\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/P\n",
    "\n",
    "    fbeta05 = ((1 + 0.05**2)*precision*recall)/(0.05**2*precision + recall)\n",
    "    fbeta5 = ((1 + 5**2)*precision*recall)/(5**2*precision + recall)\n",
    "    fbeta2 = ((1 + 2**2)*precision*recall)/(2**2*precision + recall)\n",
    "    fbeta3 = ((1 + 3**2)*precision*recall)/(3**2*precision + recall)\n",
    "\n",
    "    fbeta05_all.append(fbeta05)\n",
    "    fbeta5_all.append(fbeta5)\n",
    "    fbeta2_all.append(fbeta2)\n",
    "    fbeta3_all.append(fbeta3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 0.27310924369747897),\n",
       " (0.0198989898989899, 0.29235382308845576),\n",
       " (0.029797979797979796, 0.3072248480756246),\n",
       " (0.039696969696969696, 0.3204977694294435),\n",
       " (0.049595959595959596, 0.33163265306122447),\n",
       " (0.059494949494949496, 0.34227683049147445),\n",
       " (0.06939393939393938, 0.3521671826625387),\n",
       " (0.07929292929292929, 0.3599683544303797),\n",
       " (0.08919191919191918, 0.3681229773462783),\n",
       " (0.09909090909090908, 0.37541254125412543),\n",
       " (0.10898989898989898, 0.38256726457399104),\n",
       " (0.11888888888888888, 0.39156626506024095),\n",
       " (0.12878787878787878, 0.39819136522753784),\n",
       " (0.1386868686868687, 0.4052850356294537),\n",
       " (0.1485858585858586, 0.411144578313253),\n",
       " (0.15848484848484848, 0.4187116564417177),\n",
       " (0.16838383838383839, 0.42483660130718953),\n",
       " (0.1782828282828283, 0.42992125984251967),\n",
       " (0.18818181818181817, 0.43735982057033007),\n",
       " (0.19808080808080808, 0.4446254071661238),\n",
       " (0.207979797979798, 0.4512396694214876),\n",
       " (0.21787878787878787, 0.45851528384279483),\n",
       " (0.22777777777777777, 0.46412784767086024),\n",
       " (0.23767676767676768, 0.4702032380296245),\n",
       " (0.24757575757575756, 0.4764397905759163),\n",
       " (0.25747474747474747, 0.481651376146789),\n",
       " (0.2673737373737374, 0.4878048780487805),\n",
       " (0.2772727272727273, 0.4925751539297356),\n",
       " (0.2871717171717172, 0.4981684981684982),\n",
       " (0.29707070707070704, 0.5037037037037037),\n",
       " (0.30696969696969695, 0.5048435171385992),\n",
       " (0.31686868686868686, 0.5105501130369254),\n",
       " (0.32676767676767676, 0.5125284738041003),\n",
       " (0.33666666666666667, 0.5138036809815951),\n",
       " (0.3465656565656566, 0.5197827773467805),\n",
       " (0.3564646464646465, 0.5249705072748722),\n",
       " (0.36636363636363634, 0.5279872965462485),\n",
       " (0.37626262626262624, 0.5326391670004005),\n",
       " (0.38616161616161615, 0.5393349553933496),\n",
       " (0.39606060606060606, 0.5464256368118324),\n",
       " (0.40595959595959596, 0.5546253662620343),\n",
       " (0.41585858585858587, 0.5614406779661016),\n",
       " (0.4257575757575757, 0.5638615976078599),\n",
       " (0.43565656565656563, 0.5632283124730253),\n",
       " (0.44555555555555554, 0.5701179554390564),\n",
       " (0.45545454545454545, 0.5728709394205443),\n",
       " (0.46535353535353535, 0.5770084332001775),\n",
       " (0.47525252525252526, 0.5756358768406961),\n",
       " (0.4851515151515151, 0.5751014884979703),\n",
       " (0.495050505050505, 0.5790190735694823),\n",
       " (0.5049494949494949, 0.5778894472361809),\n",
       " (0.5148484848484849, 0.5832180728446288),\n",
       " (0.5247474747474747, 0.5863192182410423),\n",
       " (0.5346464646464646, 0.5778301886792453),\n",
       " (0.5445454545454546, 0.5828953655040612),\n",
       " (0.5544444444444444, 0.5777563793933559),\n",
       " (0.5643434343434344, 0.5728912725499756),\n",
       " (0.5742424242424242, 0.574656188605108),\n",
       " (0.5841414141414141, 0.5662710187932739),\n",
       " (0.594040404040404, 0.5669330669330669),\n",
       " (0.6039393939393939, 0.5681246857717446),\n",
       " (0.6138383838383838, 0.5688775510204082),\n",
       " (0.6237373737373737, 0.5684156378600823),\n",
       " (0.6336363636363637, 0.5642633228840126),\n",
       " (0.6435353535353535, 0.5649867374005306),\n",
       " (0.6534343434343434, 0.5663430420711973),\n",
       " (0.6633333333333333, 0.5664488017429193),\n",
       " (0.6732323232323232, 0.5610834715312327),\n",
       " (0.6831313131313131, 0.5412226584408301),\n",
       " (0.693030303030303, 0.5321570859419466),\n",
       " (0.702929292929293, 0.5238917674150834),\n",
       " (0.7128282828282828, 0.5260081823495032),\n",
       " (0.7227272727272727, 0.5224321133412043),\n",
       " (0.7326262626262626, 0.5230125523012552),\n",
       " (0.7425252525252525, 0.5090909090909091),\n",
       " (0.7524242424242424, 0.4975429975429976),\n",
       " (0.7623232323232323, 0.49440298507462693),\n",
       " (0.7722222222222221, 0.48619824341279794),\n",
       " (0.7821212121212121, 0.4704386522568341),\n",
       " (0.792020202020202, 0.4656390494540783),\n",
       " (0.8019191919191919, 0.4471279373368146),\n",
       " (0.8118181818181818, 0.4274353876739563),\n",
       " (0.8217171717171717, 0.40933694181326113),\n",
       " (0.8316161616161616, 0.3851444291609354),\n",
       " (0.8415151515151514, 0.36363636363636365),\n",
       " (0.8514141414141414, 0.3411513859275054),\n",
       " (0.8613131313131313, 0.3136265320836337),\n",
       " (0.8712121212121212, 0.2891654465592972),\n",
       " (0.8811111111111111, 0.2680565897244974),\n",
       " (0.891010101010101, 0.2322924600152323),\n",
       " (0.9009090909090909, 0.2018633540372671),\n",
       " (0.9108080808080807, 0.16733067729083664),\n",
       " (0.9207070707070707, 0.1493139628732849),\n",
       " (0.9306060606060605, 0.13082583810302537),\n",
       " (0.9405050505050505, 0.11194029850746268),\n",
       " (0.9504040404040404, 0.0759493670886076),\n",
       " (0.9603030303030302, 0.05194805194805195),\n",
       " (0.9702020202020202, 0.030837004405286347),\n",
       " (0.98010101010101, 0.022222222222222223),\n",
       " (0.99, 0.009041591320072331)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(cutoffs,fbeta2_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycutoff=cutoffs[fbeta2_all==max(fbeta2_all)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5247474747474747"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycutoff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score=logr.predict_proba(bd_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03062389, 0.36667554, 0.70862707, ..., 0.42172466, 0.61058824,\n",
       "       0.05623112])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes = test_score > mycutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, ..., False,  True, False])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes = (test_score > mycutoff).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(test_classes, columns=['V86'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V86\n",
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       1\n",
       "4       0\n",
       "...   ...\n",
       "3995    0\n",
       "3996    0\n",
       "3997    0\n",
       "3998    1\n",
       "3999    0\n",
       "\n",
       "[4000 rows x 1 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(\"Nitesh_Bhosle_project2(carvan)_p2_Logistic_Regression.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## f beta score by using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2_pred = grid_search.predict(x_test1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8012928496441383"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test1 , y_train_2_pred , average=\"weighted\" , beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## f beta score by using logr.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2_pred11 = logr.predict(x_test1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8012928496441383"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test1 , y_train_2_pred11 , average=\"weighted\" , beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test prediction using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = grid_search.predict_proba(bd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96937611, 0.03062389],\n",
       "       [0.63332446, 0.36667554],\n",
       "       [0.29137293, 0.70862707],\n",
       "       ...,\n",
       "       [0.57827534, 0.42172466],\n",
       "       [0.38941176, 0.61058824],\n",
       "       [0.94376888, 0.05623112]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test prediction using logr.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction11 = logr.predict_proba(bd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96937611, 0.03062389],\n",
       "       [0.63332446, 0.36667554],\n",
       "       [0.29137293, 0.70862707],\n",
       "       ...,\n",
       "       [0.57827534, 0.42172466],\n",
       "       [0.38941176, 0.61058824],\n",
       "       [0.94376888, 0.05623112]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hard classess (grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hard_classes = (test_prediction[:,1]>0.8012928496441383).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hard_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_hard_classes, columns=['V86'])\n",
    "df.to_csv(\"Submission_Project2_Logistic_Regression_Submission_002.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V86\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "...   ...\n",
       "3995    0\n",
       "3996    0\n",
       "3997    0\n",
       "3998    0\n",
       "3999    0\n",
       "\n",
       "[4000 rows x 1 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hard class (logr.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hard_classes11 = (test_prediction11[:,1]>0.8012928496441383).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hard_classes11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = pd.DataFrame(test_hard_classes, columns=['V86'])\n",
    "df.to_csv(\"Submission_Project2_Logistic_Regression(logr.predict)_Submission_002.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V86\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "...   ...\n",
       "3995    0\n",
       "3996    0\n",
       "3997    0\n",
       "3998    0\n",
       "3999    0\n",
       "\n",
       "[4000 rows x 1 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = LogisticRegression(penalty=\"l1\",class_weight=\"balanced\",random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l1', random_state=2,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6813761467889908"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score model performance on the test data\n",
    "roc_auc_score(y_test1,logr.predict(x_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_score=pd.Series(list(zip(*logr.predict_proba(x_train1)))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs=np.linspace(0,1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS_cut=[]\n",
    "for cutoff in cutoffs:\n",
    "    predicted=pd.Series([0]*len(y_train1))\n",
    "    predicted[prob_score>cutoff]=1\n",
    "    df=pd.DataFrame(list(zip(y_train1,predicted)),columns=[\"real\",\"predicted\"])\n",
    "    TP=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==1) ])\n",
    "    FP=len(df[(df[\"real\"]==0) &(df[\"predicted\"]==1) ])\n",
    "    TN=len(df[(df[\"real\"]==0) &(df[\"predicted\"]==0) ])\n",
    "    FN=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==0) ])\n",
    "    P=TP+FN\n",
    "    N=TN+FP\n",
    "    KS=(TP/P)-(FP/N)\n",
    "    KS_cut.append(KS)\n",
    "\n",
    "cutoff_data=pd.DataFrame(list(zip(cutoffs,KS_cut)),columns=[\"cutoff\",\"KS\"])\n",
    "\n",
    "KS_cutoff=cutoff_data[cutoff_data[\"KS\"]==cutoff_data[\"KS\"].max()][\"cutoff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix :\n",
      " \n",
      "  predicted    0    1\n",
      "real               \n",
      "0.0        857  233\n",
      "1.0         32   43\n"
     ]
    }
   ],
   "source": [
    "# Performance on test data\n",
    "prob_score_test=pd.Series(list(zip(*logr.predict_proba(x_test1)))[1])\n",
    "\n",
    "predicted_test=pd.Series([0]*len(y_test1))\n",
    "predicted_test[prob_score_test>float(KS_cutoff)]=1\n",
    "\n",
    "df_test=pd.DataFrame(list(zip(y_test1,predicted_test)),columns=[\"real\",\"predicted\"])\n",
    "\n",
    "k=pd.crosstab(df_test['real'],df_test[\"predicted\"])\n",
    "print('confusion matrix :\\n \\n ',k)\n",
    "TN=k.iloc[0,0]\n",
    "TP=k.iloc[1,1]\n",
    "FP=k.iloc[0,1]\n",
    "FN=k.iloc[1,0]\n",
    "P=TP+FN\n",
    "N=TN+FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7725321888412017"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of test\n",
    "(TP+TN)/(P+N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5733333333333334"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sensitivity on test\n",
    "TP/P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7862385321100918"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specificity on test\n",
    "TN/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs=np.linspace(0.010,0.99,100)\n",
    "def Fbeta_perf(beta,cutoffs,y_train1,prob_score):\n",
    "    FB_cut=[]\n",
    "    for cutoff in cutoffs:\n",
    "        predicted=pd.Series([0]*len(y_train1))\n",
    "        predicted[prob_score>cutoff]=1\n",
    "        df=pd.DataFrame(list(zip(y_train1,predicted)),columns=[\"real\",\"predicted\"])\n",
    "\n",
    "        TP=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==1) ])\n",
    "        FP=len(df[(df[\"real\"]==0) &(df[\"predicted\"]==1) ])\n",
    "        FN=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==0) ])\n",
    "        P=TP+FN\n",
    "        \n",
    "        \n",
    "        Precision=TP/(TP+FP)\n",
    "        Recall=TP/P\n",
    "        FB=(1+beta**2)*Precision*Recall/((beta**2)*Precision+Recall)\n",
    "        FB_cut.append(FB)\n",
    "\n",
    "    cutoff_data=pd.DataFrame(list(zip(cutoffs,FB_cut)),columns=[\"cutoff\",\"FB\"])\n",
    "\n",
    "    FB_cutoff=cutoff_data[cutoff_data[\"FB\"]==cutoff_data[\"FB\"].max()][\"cutoff\"]\n",
    "\n",
    "    prob_score_test=pd.Series(list(zip(*logr.predict_proba(x_test1)))[1])\n",
    "\n",
    "    predicted_test=pd.Series([0]*len(y_test1))\n",
    "    predicted_test[prob_score_test>float(FB_cutoff)]=1\n",
    "\n",
    "    df_test=pd.DataFrame(list(zip(y_test1,predicted_test)),columns=[\"real\",\"predicted\"])\n",
    "\n",
    "    k=pd.crosstab(df_test['real'],df_test[\"predicted\"])\n",
    "    \n",
    "#print('confusion matrix :\\n \\n ',k)\n",
    "    TN=k.iloc[0,0]\n",
    "    TP=k.iloc[1,1]\n",
    "    FP=k.iloc[0,1]\n",
    "    FN=k.iloc[1,0]\n",
    "    P=TP+FN\n",
    "    N=TN+FP\n",
    "    print('For beta :',beta)\n",
    "    print('Accuracy is :',(TP+TN)/(P+N))\n",
    "    print('Sensitivity is :',(TP/P))\n",
    "    print('Specificity is :',(TN/N))\n",
    "    print('\\n \\n \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For beta : 0.5\n",
      "Accuracy is : 0.8763948497854077\n",
      "Sensitivity is : 0.3333333333333333\n",
      "Specificity is : 0.9137614678899083\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "For beta : 1\n",
      "Accuracy is : 0.8446351931330472\n",
      "Sensitivity is : 0.37333333333333335\n",
      "Specificity is : 0.8770642201834863\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "For beta : 2\n",
      "Accuracy is : 0.7931330472103004\n",
      "Sensitivity is : 0.56\n",
      "Specificity is : 0.8091743119266055\n",
      "\n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Fbeta_perf(0.5,cutoffs,y_train1,prob_score)\n",
    "Fbeta_perf(1,cutoffs,y_train1,prob_score)\n",
    "Fbeta_perf(2,cutoffs,y_train1,prob_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01      , 0.01989899, 0.02979798, 0.03969697, 0.04959596,\n",
       "       0.05949495, 0.06939394, 0.07929293, 0.08919192, 0.09909091,\n",
       "       0.1089899 , 0.11888889, 0.12878788, 0.13868687, 0.14858586,\n",
       "       0.15848485, 0.16838384, 0.17828283, 0.18818182, 0.19808081,\n",
       "       0.2079798 , 0.21787879, 0.22777778, 0.23767677, 0.24757576,\n",
       "       0.25747475, 0.26737374, 0.27727273, 0.28717172, 0.29707071,\n",
       "       0.3069697 , 0.31686869, 0.32676768, 0.33666667, 0.34656566,\n",
       "       0.35646465, 0.36636364, 0.37626263, 0.38616162, 0.39606061,\n",
       "       0.4059596 , 0.41585859, 0.42575758, 0.43565657, 0.44555556,\n",
       "       0.45545455, 0.46535354, 0.47525253, 0.48515152, 0.49505051,\n",
       "       0.50494949, 0.51484848, 0.52474747, 0.53464646, 0.54454545,\n",
       "       0.55444444, 0.56434343, 0.57424242, 0.58414141, 0.5940404 ,\n",
       "       0.60393939, 0.61383838, 0.62373737, 0.63363636, 0.64353535,\n",
       "       0.65343434, 0.66333333, 0.67323232, 0.68313131, 0.6930303 ,\n",
       "       0.70292929, 0.71282828, 0.72272727, 0.73262626, 0.74252525,\n",
       "       0.75242424, 0.76232323, 0.77222222, 0.78212121, 0.7920202 ,\n",
       "       0.80191919, 0.81181818, 0.82171717, 0.83161616, 0.84151515,\n",
       "       0.85141414, 0.86131313, 0.87121212, 0.88111111, 0.8910101 ,\n",
       "       0.90090909, 0.91080808, 0.92070707, 0.93060606, 0.94050505,\n",
       "       0.95040404, 0.96030303, 0.97020202, 0.98010101, 0.99      ])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "train_score=logr.predict_proba(x_train1)[:,1] # the predicted response variablevalues\n",
    "real=y_train1 # the actual response variable values\n",
    "print(logr.classes_) # In order to find the probability of which column is for outcome 1 and which for outcome 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS_all=[]\n",
    "fbeta05_all=[]\n",
    "fbeta5_all=[]\n",
    "fbeta2_all=[]\n",
    "\n",
    "for cutoff in cutoffs:\n",
    "\n",
    "    predicted=(train_score>cutoff).astype(int)\n",
    "\n",
    "    TP=((predicted==1) & (real==1)).sum()\n",
    "    TN=((predicted==0) & (real==0)).sum()\n",
    "    FP=((predicted==1) & (real==0)).sum()\n",
    "    FN=((predicted==0) & (real==1)).sum()\n",
    "\n",
    "    P=TP+FN\n",
    "    N=TN+FP\n",
    "\n",
    "    KS=(TP/P)-(FP/N)\n",
    "\n",
    "    KS_all.append(KS)\n",
    "\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/P\n",
    "\n",
    "    fbeta05 = ((1 + 0.05**2)*precision*recall)/(0.05**2*precision + recall)\n",
    "    fbeta5 = ((1 + 5**2)*precision*recall)/(5**2*precision + recall)\n",
    "    fbeta2 = ((1 + 2**2)*precision*recall)/(2**2*precision + recall)\n",
    "\n",
    "    fbeta05_all.append(fbeta05)\n",
    "    fbeta5_all.append(fbeta5)\n",
    "    fbeta2_all.append(fbeta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 0.27310924369747897),\n",
       " (0.0198989898989899, 0.29235382308845576),\n",
       " (0.029797979797979796, 0.3072248480756246),\n",
       " (0.039696969696969696, 0.3204977694294435),\n",
       " (0.049595959595959596, 0.33163265306122447),\n",
       " (0.059494949494949496, 0.34227683049147445),\n",
       " (0.06939393939393938, 0.35225806451612907),\n",
       " (0.07929292929292929, 0.3599683544303797),\n",
       " (0.08919191919191918, 0.3681229773462783),\n",
       " (0.09909090909090908, 0.37541254125412543),\n",
       " (0.10898989898989898, 0.38256726457399104),\n",
       " (0.11888888888888888, 0.39156626506024095),\n",
       " (0.12878787878787878, 0.39819136522753784),\n",
       " (0.1386868686868687, 0.4052850356294537),\n",
       " (0.1485858585858586, 0.411144578313253),\n",
       " (0.15848484848484848, 0.4187116564417177),\n",
       " (0.16838383838383839, 0.42483660130718953),\n",
       " (0.1782828282828283, 0.42992125984251967),\n",
       " (0.18818181818181817, 0.43735982057033007),\n",
       " (0.19808080808080808, 0.4446254071661238),\n",
       " (0.207979797979798, 0.4512396694214876),\n",
       " (0.21787878787878787, 0.45851528384279483),\n",
       " (0.22777777777777777, 0.46412784767086024),\n",
       " (0.23767676767676768, 0.4702032380296245),\n",
       " (0.24757575757575756, 0.4764397905759163),\n",
       " (0.25747474747474747, 0.481651376146789),\n",
       " (0.2673737373737374, 0.4878048780487805),\n",
       " (0.2772727272727273, 0.4925751539297356),\n",
       " (0.2871717171717172, 0.4981684981684982),\n",
       " (0.29707070707070704, 0.5037037037037037),\n",
       " (0.30696969696969695, 0.5048435171385992),\n",
       " (0.31686868686868686, 0.5105501130369254),\n",
       " (0.32676767676767676, 0.5125284738041003),\n",
       " (0.33666666666666667, 0.5138036809815951),\n",
       " (0.3465656565656566, 0.5197827773467805),\n",
       " (0.3564646464646465, 0.5249705072748722),\n",
       " (0.36636363636363634, 0.5277777777777778),\n",
       " (0.37626262626262624, 0.5326391670004005),\n",
       " (0.38616161616161615, 0.5393349553933496),\n",
       " (0.39606060606060606, 0.5464256368118324),\n",
       " (0.40595959595959596, 0.5546253662620343),\n",
       " (0.41585858585858587, 0.5614406779661016),\n",
       " (0.4257575757575757, 0.5638615976078599),\n",
       " (0.43565656565656563, 0.5632283124730253),\n",
       " (0.44555555555555554, 0.5701179554390564),\n",
       " (0.45545454545454545, 0.5728709394205443),\n",
       " (0.46535353535353535, 0.5770084332001775),\n",
       " (0.47525252525252526, 0.5756358768406961),\n",
       " (0.4851515151515151, 0.5753610108303249),\n",
       " (0.495050505050505, 0.5790190735694823),\n",
       " (0.5049494949494949, 0.5778894472361809),\n",
       " (0.5148484848484849, 0.5832180728446288),\n",
       " (0.5247474747474747, 0.5863192182410423),\n",
       " (0.5346464646464646, 0.5778301886792453),\n",
       " (0.5445454545454546, 0.5828953655040612),\n",
       " (0.5544444444444444, 0.5777563793933559),\n",
       " (0.5643434343434344, 0.5728912725499756),\n",
       " (0.5742424242424242, 0.574656188605108),\n",
       " (0.5841414141414141, 0.5662710187932739),\n",
       " (0.594040404040404, 0.5669330669330669),\n",
       " (0.6039393939393939, 0.5681246857717446),\n",
       " (0.6138383838383838, 0.5688775510204082),\n",
       " (0.6237373737373737, 0.5684156378600823),\n",
       " (0.6336363636363637, 0.5642633228840126),\n",
       " (0.6435353535353535, 0.5649867374005306),\n",
       " (0.6534343434343434, 0.5663430420711973),\n",
       " (0.6633333333333333, 0.5664488017429193),\n",
       " (0.6732323232323232, 0.5610834715312327),\n",
       " (0.6831313131313131, 0.5412226584408301),\n",
       " (0.693030303030303, 0.5321570859419466),\n",
       " (0.702929292929293, 0.5238917674150834),\n",
       " (0.7128282828282828, 0.5260081823495032),\n",
       " (0.7227272727272727, 0.5224321133412043),\n",
       " (0.7326262626262626, 0.5230125523012552),\n",
       " (0.7425252525252525, 0.5090909090909091),\n",
       " (0.7524242424242424, 0.4975429975429976),\n",
       " (0.7623232323232323, 0.49440298507462693),\n",
       " (0.7722222222222221, 0.48619824341279794),\n",
       " (0.7821212121212121, 0.4704386522568341),\n",
       " (0.792020202020202, 0.4656390494540783),\n",
       " (0.8019191919191919, 0.4471279373368146),\n",
       " (0.8118181818181818, 0.4274353876739563),\n",
       " (0.8217171717171717, 0.40933694181326113),\n",
       " (0.8316161616161616, 0.3851444291609354),\n",
       " (0.8415151515151514, 0.36363636363636365),\n",
       " (0.8514141414141414, 0.3411513859275054),\n",
       " (0.8613131313131313, 0.3136265320836337),\n",
       " (0.8712121212121212, 0.2891654465592972),\n",
       " (0.8811111111111111, 0.2680565897244974),\n",
       " (0.891010101010101, 0.2322924600152323),\n",
       " (0.9009090909090909, 0.2018633540372671),\n",
       " (0.9108080808080807, 0.16733067729083664),\n",
       " (0.9207070707070707, 0.1493139628732849),\n",
       " (0.9306060606060605, 0.13082583810302537),\n",
       " (0.9405050505050505, 0.11194029850746268),\n",
       " (0.9504040404040404, 0.0759493670886076),\n",
       " (0.9603030303030302, 0.05194805194805195),\n",
       " (0.9702020202020202, 0.030837004405286347),\n",
       " (0.98010101010101, 0.022222222222222223),\n",
       " (0.99, 0.009041591320072331)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(cutoffs,fbeta2_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5247474747474747"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycutoff=cutoffs[fbeta2_all==max(fbeta2_all)][0]\n",
    "mycutoff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03062646, 0.36667271, 0.70862848, ..., 0.42171424, 0.61058602,\n",
       "       0.05623096])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score=logr.predict_proba(bd_test)[:,1]\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes=(test_score>mycutoff).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5247474747474747"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_classes, columns=['V86'])\n",
    "df.to_csv(\"Submission_Project2_Logistic_Regression_Submission_002.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
